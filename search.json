[{"path":"https://jkunst.com/klassets/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 klassets authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jkunst.com/klassets/articles/Binary-classification.html","id":"generating-data-set","dir":"Articles","previous_headings":"","what":"Generating data set","title":"Binary classification","text":"main function sim_response_xy, need define: number observations simulate. Distributions sample \\(x\\) \\(y\\). example purrr::partial(runif, min = -1, max = 1). function define relation response \\(x\\) \\(y\\), example function(x, y) x > y function must return logical value. number define noise generated data.","code":"library(klassets) library(ggplot2) library(patchwork)  set.seed(123)  df_default <- sim_response_xy(n = 500)  df_default #> # A tibble: 500 × 3 #>    response       x        y #>    <fct>      <dbl>    <dbl> #>  1 FALSE    -0.425  -0.293   #>  2 TRUE      0.577  -0.267   #>  3 FALSE    -0.182  -0.426   #>  4 TRUE      0.766  -0.840   #>  5 TRUE      0.881  -0.269   #>  6 FALSE    -0.909  -0.644   #>  7 FALSE     0.0562  0.0721  #>  8 TRUE      0.785   0.00790 #>  9 TRUE      0.103   0.890   #> 10 TRUE     -0.0868 -0.317   #> # … with 490 more rows  plot(df_default) df <- sim_response_xy(   n = 500,    x_dist = purrr::partial(runif, min = -1, max = 1),   # relationship = function(x, y) sqrt(abs(x)) - x - 0.5 > sin(y),   relationship = function(x, y) sin(x*pi) > sin(y*pi),   noise = 0.15   )  plot(df)"},{"path":[]},{"path":"https://jkunst.com/klassets/articles/Binary-classification.html","id":"logistic-regression","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Logistic Regression","title":"Binary classification","text":"default model use order = 1 variables, .e, response ~ x + y. can get better fit increase order.  Testing various orders.","code":"df_lr <- fit_logistic_regression(df)  df_lr #> # A tibble: 500 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl>      <dbl> #>  1 TRUE      0.876  -0.681       0.885 #>  2 TRUE      0.976  -0.711       0.899 #>  3 TRUE     -0.0874 -0.702       0.745 #>  4 FALSE    -0.539   0.0289      0.385 #>  5 TRUE      0.391  -0.0143      0.637 #>  6 FALSE     0.113   0.233       0.478 #>  7 TRUE      0.169  -0.105       0.614 #>  8 FALSE    -0.133  -0.889       0.785 #>  9 FALSE    -0.148  -0.989       0.807 #> 10 TRUE      0.194  -0.556       0.760 #> # … with 490 more rows  plot(df_lr) df_lr2 <- fit_logistic_regression(df, order = 4, stepwise = TRUE)  attr(df_lr2, \"model\") #>  #> Call:  glm(formula = response ~ x + y + x_3 + y_3, family = binomial,  #>     data = df) #>  #> Coefficients: #> (Intercept)            x            y          x_3          y_3   #>      0.1533       3.3121      -4.4480      -3.3786       4.6436   #>  #> Degrees of Freedom: 499 Total (i.e. Null);  495 Residual #> Null Deviance:       690.8  #> Residual Deviance: 518   AIC: 528  plot(df_lr2) orders <- c(1, 2, 3, 4)  orders |>    purrr::map(fit_logistic_regression, df = df) |>    purrr::map(plot) |>    purrr::reduce(`+`) +   patchwork::plot_layout(guides = \"collect\") &   theme_void() + theme(legend.position = \"none\")"},{"path":"https://jkunst.com/klassets/articles/Binary-classification.html","id":"classification-tree","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Classification Tree","title":"Binary classification","text":"(partykit::ctree)   region filled probability respective node. can specify type prediction using type argument. case response.  now node.","code":"df_rt <- fit_classification_tree(df)  plot(df_rt) plot(fit_classification_tree(df, alpha = 0.25)) df_rt_response <- fit_classification_tree(df, type = \"response\")  df_rt_response #> # A tibble: 500 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl> <fct>      #>  1 TRUE      0.876  -0.681  TRUE       #>  2 TRUE      0.976  -0.711  TRUE       #>  3 TRUE     -0.0874 -0.702  TRUE       #>  4 FALSE    -0.539   0.0289 FALSE      #>  5 TRUE      0.391  -0.0143 TRUE       #>  6 FALSE     0.113   0.233  FALSE      #>  7 TRUE      0.169  -0.105  TRUE       #>  8 FALSE    -0.133  -0.889  TRUE       #>  9 FALSE    -0.148  -0.989  TRUE       #> 10 TRUE      0.194  -0.556  TRUE       #> # … with 490 more rows  plot(df_rt_response) df_rt_node <- fit_classification_tree(df, type = \"node\", maxdepth = 3)  df_rt_node #> # A tibble: 500 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl>      <int> #>  1 TRUE      0.876  -0.681           4 #>  2 TRUE      0.976  -0.711           4 #>  3 TRUE     -0.0874 -0.702           4 #>  4 FALSE    -0.539   0.0289          3 #>  5 TRUE      0.391  -0.0143          4 #>  6 FALSE     0.113   0.233           6 #>  7 TRUE      0.169  -0.105           4 #>  8 FALSE    -0.133  -0.889           4 #>  9 FALSE    -0.148  -0.989           4 #> 10 TRUE      0.194  -0.556           4 #> # … with 490 more rows  plot(df_rt_node) plot(attr(df_rt_node, \"model\"))"},{"path":"https://jkunst.com/klassets/articles/Binary-classification.html","id":"k-nearest-neighbours","dir":"Articles","previous_headings":"Fit classification algorithms","what":"K Nearest Neighbours","title":"Binary classification","text":"class::knn implementation.","code":"# defaults to prob fit_knn(df) #> # A tibble: 500 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl>      <dbl> #>  1 TRUE      0.876  -0.681         1   #>  2 TRUE      0.976  -0.711         1   #>  3 TRUE     -0.0874 -0.702         1   #>  4 FALSE    -0.539   0.0289        0.9 #>  5 TRUE      0.391  -0.0143        0.8 #>  6 FALSE     0.113   0.233         0.8 #>  7 TRUE      0.169  -0.105         0.9 #>  8 FALSE    -0.133  -0.889         0.8 #>  9 FALSE    -0.148  -0.989         0.6 #> 10 TRUE      0.194  -0.556         0.7 #> # … with 490 more rows  fit_knn(df, type = \"response\") #> # A tibble: 500 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl> <fct>      #>  1 TRUE      0.876  -0.681  TRUE       #>  2 TRUE      0.976  -0.711  TRUE       #>  3 TRUE     -0.0874 -0.702  TRUE       #>  4 FALSE    -0.539   0.0289 FALSE      #>  5 TRUE      0.391  -0.0143 TRUE       #>  6 FALSE     0.113   0.233  FALSE      #>  7 TRUE      0.169  -0.105  TRUE       #>  8 FALSE    -0.133  -0.889  TRUE       #>  9 FALSE    -0.148  -0.989  TRUE       #> 10 TRUE      0.194  -0.556  TRUE       #> # … with 490 more rows  plot(fit_knn(df)) neighbours <- c(3, 10, 50, 300)  purrr::map(neighbours, fit_knn, df = df) |>    purrr::map(plot) |>    purrr::reduce(`+`) +   patchwork::plot_layout(guides = \"collect\") &   theme_void() + theme(legend.position = \"none\") purrr::map(neighbours, fit_knn, df = df, type = \"response\") |>    purrr::map(plot) |>    purrr::reduce(`+`) +   patchwork::plot_layout(guides = \"collect\")  &   theme_void() + theme(legend.position = \"none\")"},{"path":"https://jkunst.com/klassets/articles/Binary-classification.html","id":"random-forest","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Random Forest","title":"Binary classification","text":"Using ranger::ranger function.","code":"df_crf <- fit_classification_random_forest(df)  plot(df_crf) df_crf #> # A tibble: 500 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl>      <dbl> #>  1 TRUE      0.876  -0.681       0.984 #>  2 TRUE      0.976  -0.711       0.952 #>  3 TRUE     -0.0874 -0.702       0.905 #>  4 FALSE    -0.539   0.0289      0.173 #>  5 TRUE      0.391  -0.0143      0.899 #>  6 FALSE     0.113   0.233       0.264 #>  7 TRUE      0.169  -0.105       0.946 #>  8 FALSE    -0.133  -0.889       0.702 #>  9 FALSE    -0.148  -0.989       0.500 #> 10 TRUE      0.194  -0.556       0.922 #> # … with 490 more rows"},{"path":"https://jkunst.com/klassets/articles/Clustering.html","id":"generating-data-set","dir":"Articles","previous_headings":"","what":"Generating data set","title":"Clustering","text":"main function sim_groups, need define: number observations draw. number groups sample. optional argument define proportion group.","code":"library(klassets)  set.seed(123)  df <- sim_groups(n = 500, groups = 3)  plot(df)"},{"path":[]},{"path":"https://jkunst.com/klassets/articles/Clustering.html","id":"k-means-statskmeans","dir":"Articles","previous_headings":"Fit cluster algorithms","what":"K-means stats::kmeans","title":"Clustering","text":"can apply stats::kmeans using fit_statskmeans_clust.","code":"dfc1 <- fit_statskmeans(df, centers = 2)  plot(dfc1)"},{"path":"https://jkunst.com/klassets/articles/Clustering.html","id":"hierarchical-clustering-statshclust","dir":"Articles","previous_headings":"Fit cluster algorithms","what":"Hierarchical Clustering stats::hclust","title":"Clustering","text":"","code":"dfhc <- fit_hclust(df, k = 2)  plot(dfhc)"},{"path":"https://jkunst.com/klassets/articles/Clustering.html","id":"k-means-basic-klassets-implementation","dir":"Articles","previous_headings":"Fit cluster algorithms","what":"K-means: Basic {klassets} implementation","title":"Clustering","text":"use basic K-means implementation :  benefit? second one use helper function kmeans_iterations keep iteration see algorithm converges.  Now can use gganimate package using object result kmeans_iterations due classification every point every step: can take output function data use gganimate make animation using klassets home page. code used animation can found package using:","code":"set.seed(234)  dfc2 <- fit_kmeans(df, centers = 2, max_iteration = 6)  plot(dfc2) set.seed(234)  kmi <- kmeans_iterations(df, centers = 2, max_iteration = 6)  plot(kmi) kmi #> $points #> # A tibble: 2,988 × 6 #>    iteration    id group      x     y cluster #>        <int> <int> <chr>  <dbl> <dbl> <fct>   #>  1         1     1 1      4.53   8.60 NA      #>  2         1     2 1      5.57   6.42 NA      #>  3         1     3 1      2.62   6.28 NA      #>  4         1     4 1      4.82   7.41 NA      #>  5         1     5 1      0.583  2.50 NA      #>  6         1     6 1     -5.49   8.30 NA      #>  7         1     7 1      3.59   9.44 NA      #>  8         1     8 1     -0.224  3.95 NA      #>  9         1     9 1     -2.62  10.7  NA      #> 10         1    10 1     -0.695  8.74 NA      #> # … with 2,978 more rows #>  #> $centers #> # A tibble: 12 × 4 #>    iteration cluster     cx    cy #>        <int> <fct>    <dbl> <dbl> #>  1         1 A       -4.67   5.85 #>  2         1 B        3.70  -7.21 #>  3         2 A        0.327  5.85 #>  4         2 B        7.26  -1.35 #>  5         3 A        0.170  5.29 #>  6         3 B        7.65  -1.30 #>  7         4 A        0.132  5.05 #>  8         4 B        7.83  -1.27 #>  9         5 A        0.137  4.76 #> 10         5 B        8.04  -1.24 #> 11         6 A        0.155  4.57 #> 12         6 B        8.19  -1.22 #>  #> attr(,\"class\") #> [1] \"klassets_kmiterations\" \"list\" system.file(\"animation_kmeans_iterations.R\", package = \"klassets\") #> [1] \"/home/runner/work/_temp/Library/klassets/animation_kmeans_iterations.R\""},{"path":"https://jkunst.com/klassets/articles/MNIST.html","id":"data-set","dir":"Articles","previous_headings":"","what":"Data set","title":"Working on MNIST data","text":"can plot rows follows:","code":"library(klassets)  data(\"mnist_train\")  mnist_train #> # A tibble: 60,000 × 785 #>    label pixel_01x01 pixel_01x02 pixel_01x03 pixel_01x04 pixel_01x05 pixel_01x06 #>    <fct>       <dbl>       <dbl>       <dbl>       <dbl>       <dbl>       <dbl> #>  1 5               0           0           0           0           0           0 #>  2 0               0           0           0           0           0           0 #>  3 4               0           0           0           0           0           0 #>  4 1               0           0           0           0           0           0 #>  5 9               0           0           0           0           0           0 #>  6 2               0           0           0           0           0           0 #>  7 1               0           0           0           0           0           0 #>  8 3               0           0           0           0           0           0 #>  9 1               0           0           0           0           0           0 #> 10 4               0           0           0           0           0           0 #> # … with 59,990 more rows, and 778 more variables: pixel_01x07 <dbl>, #> #   pixel_01x08 <dbl>, pixel_01x09 <dbl>, pixel_01x10 <dbl>, pixel_01x11 <dbl>, #> #   pixel_01x12 <dbl>, pixel_01x13 <dbl>, pixel_01x14 <dbl>, pixel_01x15 <dbl>, #> #   pixel_01x16 <dbl>, pixel_01x17 <dbl>, pixel_01x18 <dbl>, pixel_01x19 <dbl>, #> #   pixel_01x20 <dbl>, pixel_01x21 <dbl>, pixel_01x22 <dbl>, pixel_01x23 <dbl>, #> #   pixel_01x24 <dbl>, pixel_01x25 <dbl>, pixel_01x26 <dbl>, pixel_01x27 <dbl>, #> #   pixel_01x28 <dbl>, pixel_02x01 <dbl>, pixel_02x02 <dbl>, …  dim(mnist_train) #> [1] 60000   785 mnist_plot_digits(c(1, 3, 40, 55555))"},{"path":[]},{"path":[]},{"path":[]},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"set-1-the-original","dir":"Articles","previous_headings":"The sets","what":"Set 1: The original","title":"Quasi Anscombe data sets","text":"","code":"library(klassets) library(ggplot2)  set.seed(123)  df <- sim_quasianscombe_set_1(n = 100, beta1 = 2)  plot(df) +   # xlim(0, NA) +   # ylim(0, NA) +   labs(subtitle = \"Original data set\")"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"set-4-no-linear-relationship","dir":"Articles","previous_headings":"The sets","what":"Set 4: No linear relationship","title":"Quasi Anscombe data sets","text":"","code":"func <- function(x) 1.5 * x^2  df2_1 <- sim_quasianscombe_set_2(df, residual_factor = 0, fun = func)  funktion <- function(x){ 2 * sin(x*diff(range(x))) }  df2_2 <- sim_quasianscombe_set_2(df, fun = funktion, residual_factor = 1.25)"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"set-3-extreme-values","dir":"Articles","previous_headings":"The sets","what":"Set 3: Extreme values","title":"Quasi Anscombe data sets","text":"","code":"df3_1 <- sim_quasianscombe_set_3(df, prop = 0.10)  df3_2 <- sim_quasianscombe_set_3(df, prop = 0.15, residual_factor = 0)"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"set-4-clusters","dir":"Articles","previous_headings":"The sets","what":"Set 4: Clusters","title":"Quasi Anscombe data sets","text":"","code":"df4_1 <- sim_quasianscombe_set_4(df, prop = 0.25)  df4_2 <- sim_quasianscombe_set_4(df, rescale_to = c(0, .1), prop = 0.5)"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"set-5-heteroskedasticity","dir":"Articles","previous_headings":"The sets","what":"Set 5: Heteroskedasticity","title":"Quasi Anscombe data sets","text":"","code":"df5_1 <- sim_quasianscombe_set_5(df, residual_factor = 2)  df5_2 <- sim_quasianscombe_set_5(df, fun = function(x) rev(x**2))"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"set-6-simpsons-paradox","dir":"Articles","previous_headings":"The sets","what":"Set 6: Simpson’s Paradox","title":"Quasi Anscombe data sets","text":"","code":"df6_1 <- sim_quasianscombe_set_6(df, residual_factor = 1)  df6_2 <- sim_quasianscombe_set_6(df, groups = 4, b1_factor = 0, residual_factor = 0.1)"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"combine-results","dir":"Articles","previous_headings":"","what":"Combine results","title":"Quasi Anscombe data sets","text":"[@warnes](https://github.com/warnes) gtools package","code":"library(dplyr, warn.conflicts = FALSE) library(tidyr) library(purrr) library(broom)  dfs <- list(   \"Original\" = df,   \"Set 2 v1\" = df2_1,   \"Set 2 v2\" = df2_2,   \"Set 3 v1\" = df3_1,   \"Set 3 v2\" = df3_2,   \"Set 4 v1\" = df4_1,   \"Set 4 v2\" = df4_2,   \"Set 5 v1\" = df5_1,   \"Set 5 v2\" = df5_2,   \"Set 6 v1\" = df6_1,   \"Set 6 v2\" = df6_2 )  dfs <- dfs |>    tibble::enframe(name = \"set\") |>    tidyr::unnest(cols = c(value)) stars.pval <- function(p.value) {   unclass(     symnum(p.value,       corr = FALSE, na = FALSE,       cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),       symbols = c(\"***\", \"**\", \"*\", \".\", \" \")     )   ) }"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"visual-representation-of-the-data-sets","dir":"Articles","previous_headings":"Combine results","what":"Visual representation of the data sets","title":"Quasi Anscombe data sets","text":"","code":"pxy <- ggplot(dfs, aes(x, y)) +   geom_point(shape = 21, fill = \"gray80\", color = \"gray60\") +   geom_smooth(method = \"lm\", se = FALSE, formula = y ~ x) +   facet_wrap(vars(set))  pxy"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"checking-coefficients-and-its-significance","dir":"Articles","previous_headings":"Combine results","what":"Checking Coefficients and its significance","title":"Quasi Anscombe data sets","text":"","code":"df_mods <- dfs |>    dplyr::group_nest(set) |>    dplyr::mutate(     model = map(data, lm, formula = y ~ x),     parameters = map(model, broom::tidy)     # value = map(model, coefficients),     # coef  = map(value, names)     )   dfcoef <- df_mods |>    dplyr::select(set, parameters) |>    tidyr::unnest(cols = c(parameters)) |>    dplyr::mutate(sig = stars.pval(p.value))  dfcoef #> # A tibble: 22 × 7 #>    set      term        estimate std.error statistic  p.value sig   #>    <chr>    <chr>          <dbl>     <dbl>     <dbl>    <dbl> <chr> #>  1 Original (Intercept)     2.74    0.276       9.93 1.74e-16 ***   #>  2 Original x               2.04    0.0533     38.3  1.01e-60 ***   #>  3 Set 2 v1 (Intercept)     2.74    1.18        2.33 2.20e- 2 *     #>  4 Set 2 v1 x               2.04    0.228       8.97 2.11e-14 ***   #>  5 Set 2 v2 (Intercept)     2.74    0.898       3.05 2.94e- 3 **    #>  6 Set 2 v2 x               2.04    0.174      11.8  1.95e-20 ***   #>  7 Set 3 v1 (Intercept)     2.74    1.15        2.37 1.97e- 2 *     #>  8 Set 3 v1 x               2.04    0.223       9.14 8.86e-15 ***   #>  9 Set 3 v2 (Intercept)     2.74    1.05        2.61 1.06e- 2 *     #> 10 Set 3 v2 x               2.04    0.203      10.0  9.74e-17 ***   #> # … with 12 more rows  dfcoef |>    dplyr::select(set, term, estimate) |>    tidyr::pivot_wider(names_from = \"term\", values_from = \"estimate\") #> # A tibble: 11 × 3 #>    set      `(Intercept)`     x #>    <chr>            <dbl> <dbl> #>  1 Original          2.74  2.04 #>  2 Set 2 v1          2.74  2.04 #>  3 Set 2 v2          2.74  2.04 #>  4 Set 3 v1          2.74  2.04 #>  5 Set 3 v2          2.74  2.04 #>  6 Set 4 v1          2.74  2.04 #>  7 Set 4 v2          2.74  2.04 #>  8 Set 5 v1          2.74  2.04 #>  9 Set 5 v2          2.74  2.04 #> 10 Set 6 v1          2.74  2.04 #> 11 Set 6 v2          2.74  2.04"},{"path":"https://jkunst.com/klassets/articles/Regression.html","id":"generating-data-set","dir":"Articles","previous_headings":"","what":"Generating data set","title":"Regression","text":"main function sim_xy, need define: number observations simulate. Values \\(\\beta_0\\) \\(\\beta_1\\). distribution sample \\(x\\). example stats::runif purrr::partial(stats::rnorm, mean = 5, sd = 1). function sample error values like purrr::partial(stats::rnorm, sd = 0.5).  can modify data frame get types relationships.","code":"library(klassets) library(ggplot2) library(patchwork)  set.seed(123)  df_default <- sim_xy()  df_default #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.34  3.87 #>  2  2.36  3.68 #>  3  2.53  4.78 #>  4  2.69  4.72 #>  5  2.78  3.63 #>  6  2.84  4.37 #>  7  2.95  4.03 #>  8  2.95  3.44 #>  9  2.95  4.55 #> 10  2.99  4.45 #> # … with 490 more rows  plot(df_default) df <- sim_xy(n = 1000, x_dist = runif)  df <- dplyr::mutate(df, y = y + 2*sin(5 * x) + sin(10 * x))  plot(df)"},{"path":[]},{"path":"https://jkunst.com/klassets/articles/Regression.html","id":"linear-regression","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Linear Regression","title":"Regression","text":"function uses stats::lm fit model.  default model use order = 1 variables, .e, response ~ x + y. can get better fit increase order.  Testing various orders.","code":"df_lr <- fit_linear_model(df)  df_lr #> # A tibble: 1,000 × 3 #>          x     y prediction #>      <dbl> <dbl>      <dbl> #>  1 0.00352  2.66       5.56 #>  2 0.00354  2.92       5.56 #>  3 0.00499  2.65       5.56 #>  4 0.00540  3.42       5.56 #>  5 0.00804  3.72       5.55 #>  6 0.00872  4.24       5.54 #>  7 0.00934  3.37       5.54 #>  8 0.0101   2.77       5.54 #>  9 0.0103   3.72       5.54 #> 10 0.0103   3.66       5.54 #> # … with 990 more rows  plot(df_lr) df_lr2 <- fit_linear_model(df, order = 4, stepwise = TRUE)  attr(df_lr2, \"model\") #>  #> Call: #> stats::lm(formula = y ~ x + x_2 + x_3 + x_4, data = df) #>  #> Coefficients: #> (Intercept)            x          x_2          x_3          x_4   #>       2.726       35.066     -137.903      186.228      -85.616  plot(df_lr2) orders <- c(1, 2, 3, 4)  orders |>    purrr::map(fit_linear_model, df = df) |>    purrr::map(plot) |>    purrr::reduce(`+`) +   patchwork::plot_layout(guides = \"collect\") &   theme_void() + theme(legend.position = \"none\")"},{"path":"https://jkunst.com/klassets/articles/Regression.html","id":"regression-tree","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Regression Tree","title":"Regression","text":"Internally functions uses partykit::ctree.","code":"df_rt <- fit_regression_tree(df)  plot(df_rt) plot(attr(df_rt, \"model\"))"},{"path":"https://jkunst.com/klassets/articles/Regression.html","id":"linear-model-tree","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Linear Model Tree","title":"Regression","text":"Internally functions uses partykit::mltree.","code":"df_lmt <- fit_linear_model_tree(df)  plot(df_lmt) plot(attr(df_lmt, \"model\"))"},{"path":"https://jkunst.com/klassets/articles/Regression.html","id":"random-forest","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Random Forest","title":"Regression","text":"Internally functions uses partykit::cforest.","code":"df_rf <- fit_regression_random_forest(df)  plot(df_rf) # this will be relative similar to `fit_regression_tree` due  # we are using 1 tree plot(fit_regression_random_forest(df, ntree = 1, maxdepth = 3))"},{"path":"https://jkunst.com/klassets/articles/Regression.html","id":"local-polynomial-regression-fitting-loess","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Local Polynomial Regression Fitting (LOESS)","title":"Regression","text":"Using stats::loess.","code":"df_loess <- fit_loess(df)  plot(df_loess)"},{"path":"https://jkunst.com/klassets/articles/Regression.html","id":"multivariate-adaptive-regression-splines-mars","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Multivariate Adaptive Regression Splines (MARS)","title":"Regression","text":"Using earth::earth.","code":"df_mars <- fit_mars(df)  plot(df_mars)"},{"path":"https://jkunst.com/klassets/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Joshua Kunst. Author, maintainer.","code":""},{"path":"https://jkunst.com/klassets/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kunst J (2022). klassets: Tools simulate data set teach Statical Models ML Algorithms. https://jkunst.com/klassets/, https://github.com/jbkunst/klassets.","code":"@Manual{,   title = {klassets: Tools to simulate data set to teach Statical Models and ML Algorithms},   author = {Joshua Kunst},   year = {2022},   note = {https://jkunst.com/klassets/, https://github.com/jbkunst/klassets}, }"},{"path":"https://jkunst.com/klassets/index.html","id":"klassets","dir":"","previous_headings":"","what":"Tools to simulate data set to teach Statical Models and ML Algorithms","title":"Tools to simulate data set to teach Statical Models and ML Algorithms","text":"klassets package collection functions simulate data sets : Teach Statistics Models Machine Learning algorithms works. Illustrate certain particular events heteroskedasticity Simpson’s paradox. Compare predictions modelos, example logistic regression vs decision tree vs -Nearest Neighbours.","code":""},{"path":[]},{"path":"https://jkunst.com/klassets/index.html","id":"dont-forget-to-visualize-the-data","dir":"","previous_headings":"","what":"Don’t forget to visualize the data","title":"Tools to simulate data set to teach Statical Models and ML Algorithms","text":"","code":"library(klassets)  set.seed(123)  df <- sim_quasianscombe_set_1(beta0 = 3, beta1 = 0.5)  plot(df) +   ggplot2::labs(subtitle = \"Very similar to the given parameters (3 and 0.5)\") library(patchwork)  df2 <- sim_quasianscombe_set_2(df, fun = sin) df6 <- sim_quasianscombe_set_6(df, groups = 2, b1_factor = -1)  plot(df2) + plot(df6)"},{"path":"https://jkunst.com/klassets/index.html","id":"compare-models-in-a-classifications-task","dir":"","previous_headings":"","what":"Compare models in a classifications task","title":"Tools to simulate data set to teach Statical Models and ML Algorithms","text":"can fit differents models see predictions made.","code":"df <- sim_response_xy(relationship = function(x, y) sin(x*pi) > sin(y*pi))  df #> # A tibble: 500 × 3 #>    response       x       y #>    <fct>      <dbl>   <dbl> #>  1 FALSE    -0.681   0.707  #>  2 FALSE    -0.711   0.332  #>  3 FALSE    -0.702   0.467  #>  4 TRUE      0.0289 -0.371  #>  5 TRUE     -0.0143  0.335  #>  6 TRUE      0.233  -0.0722 #>  7 FALSE    -0.105   0.301  #>  8 FALSE    -0.889   0.572  #>  9 FALSE    -0.989   0.803  #> 10 FALSE    -0.556   0.0548 #> # … with 490 more rows  plot(df) plot(fit_logistic_regression(df, order = 4)) + plot(fit_classification_tree(df))            + plot(fit_classification_random_forest(df))   + plot(fit_knn(df))                            +   plot_layout(guides = \"collect\")"},{"path":"https://jkunst.com/klassets/index.html","id":"how-k-means-works","dir":"","previous_headings":"","what":"How -means works","title":"Tools to simulate data set to teach Statical Models and ML Algorithms","text":"Another example can done klassets.","code":""},{"path":"https://jkunst.com/klassets/index.html","id":"where-to-start","dir":"","previous_headings":"","what":"Where to start","title":"Tools to simulate data set to teach Statical Models and ML Algorithms","text":"can check: vignette(\"Quasi-Anscombe-data-sets\") know sim_quasianscombe_set* functions family. vignette(\"Binary-classification\")/vignette(\"Regression\") see classifiers/regression models/methods. vignette(\"Clustering\") see clustering functions.","code":""},{"path":"https://jkunst.com/klassets/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools to simulate data set to teach Statical Models and ML Algorithms","text":"can install development version klassets GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"jbkunst/klassets\")"},{"path":"https://jkunst.com/klassets/index.html","id":"extra-info","dir":"","previous_headings":"","what":"Extra Info(?!)","title":"Tools to simulate data set to teach Statical Models and ML Algorithms","text":"name Klassets? Just weird merge Class/Klass sets. inspiration similar ideas: https://jumpingrivers.github.io/datasauRus/ https://eliocamp.github.io/metamer/ http://www.econometricsbysimulation.com/2019/03/-importance--graphing--data.html almost , approach ’s different.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_classification_random_forest.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit classification random forest to klassets_response_xy object — fit_classification_random_forest","title":"Fit classification random forest to klassets_response_xy object — fit_classification_random_forest","text":"Fit classification random forest klassets_response_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_classification_random_forest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit classification random forest to klassets_response_xy object — fit_classification_random_forest","text":"","code":"fit_classification_random_forest(   df,   type = \"prob\",   ntree = 500L,   maxdepth = NULL,   trace = FALSE,   ... )"},{"path":"https://jkunst.com/klassets/reference/fit_classification_random_forest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit classification random forest to klassets_response_xy object — fit_classification_random_forest","text":"df object sim_response_xy. type Type prediction, one prob, response, node. ntree Number trees grow forest. maxdepth Max depth trees. trace logical indicating progress bar shall printed forest grows. ... Options ranger::ranger.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_classification_random_forest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit classification random forest to klassets_response_xy object — fit_classification_random_forest","text":"","code":"set.seed(123)  df <- sim_response_xy(n = 1000, relationship = function(x, y) x**2 > sin(y))  plot(df)   dfcrf <- fit_classification_random_forest(df)  dfcrf #> # A tibble: 1,000 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl>      <dbl> #>  1 FALSE    -0.425  -0.453      0.953  #>  2 FALSE     0.577   0.188      0.754  #>  3 FALSE    -0.182  -0.680      0.696  #>  4 FALSE     0.766   0.707      0.188  #>  5 TRUE      0.881   0.695      0.646  #>  6 TRUE     -0.909  -0.0442     0.900  #>  7 FALSE     0.0562  0.547      0.0358 #>  8 FALSE     0.785  -0.409      0.959  #>  9 FALSE     0.103  -0.869      0.661  #> 10 TRUE     -0.0868 -0.119      0.691  #> # … with 990 more rows  plot(dfcrf)"},{"path":"https://jkunst.com/klassets/reference/fit_classification_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit classification tree to klassets_response_xy object — fit_classification_tree","title":"Fit classification tree to klassets_response_xy object — fit_classification_tree","text":"Fit classification tree klassets_response_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_classification_tree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit classification tree to klassets_response_xy object — fit_classification_tree","text":"","code":"fit_classification_tree(df, type = \"prob\", maxdepth = Inf, alpha = 0.05, ...)"},{"path":"https://jkunst.com/klassets/reference/fit_classification_tree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit classification tree to klassets_response_xy object — fit_classification_tree","text":"df object sim_response_xy. type Type prediction, one prob, response, node. maxdepth Max depth tree. used partykit::ctree_control. alpha Alpha value, used partykit::ctree_control ... Options partykit::ctree_control.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_classification_tree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit classification tree to klassets_response_xy object — fit_classification_tree","text":"","code":"set.seed(123)  df <- sim_response_xy(n = 1000, relationship = function(x, y) x**2 > sin(y))  plot(df)   # default type = \"prob\" df_tree_prob <- fit_classification_tree(df) df_tree_prob #> # A tibble: 1,000 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl>      <dbl> #>  1 FALSE    -0.425  -0.453       0.242 #>  2 FALSE     0.577   0.188       0.564 #>  3 FALSE    -0.182  -0.680       0.242 #>  4 FALSE     0.766   0.707       0.746 #>  5 TRUE      0.881   0.695       0.746 #>  6 TRUE     -0.909  -0.0442      0.242 #>  7 FALSE     0.0562  0.547       0.564 #>  8 FALSE     0.785  -0.409       0.242 #>  9 FALSE     0.103  -0.869       0.242 #> 10 TRUE     -0.0868 -0.119       0.242 #> # … with 990 more rows  df_tree_resp <- fit_classification_tree(df, type = \"response\") df_tree_resp #> # A tibble: 1,000 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl> <fct>      #>  1 FALSE    -0.425  -0.453  TRUE       #>  2 FALSE     0.577   0.188  FALSE      #>  3 FALSE    -0.182  -0.680  TRUE       #>  4 FALSE     0.766   0.707  FALSE      #>  5 TRUE      0.881   0.695  FALSE      #>  6 TRUE     -0.909  -0.0442 TRUE       #>  7 FALSE     0.0562  0.547  FALSE      #>  8 FALSE     0.785  -0.409  TRUE       #>  9 FALSE     0.103  -0.869  TRUE       #> 10 TRUE     -0.0868 -0.119  TRUE       #> # … with 990 more rows  df_tree_node <- fit_classification_tree(df, type = \"node\") df_tree_node #> # A tibble: 1,000 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl>      <int> #>  1 FALSE    -0.425  -0.453           2 #>  2 FALSE     0.577   0.188           4 #>  3 FALSE    -0.182  -0.680           2 #>  4 FALSE     0.766   0.707           5 #>  5 TRUE      0.881   0.695           5 #>  6 TRUE     -0.909  -0.0442          2 #>  7 FALSE     0.0562  0.547           4 #>  8 FALSE     0.785  -0.409           2 #>  9 FALSE     0.103  -0.869           2 #> 10 TRUE     -0.0868 -0.119           2 #> # … with 990 more rows  plot(df_tree_prob)  plot(df_tree_resp)  plot(df_tree_node)"},{"path":"https://jkunst.com/klassets/reference/fit_hclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Hierarchical Clustering to klassets_cluster object using stats::hclust — fit_hclust","title":"Fit Hierarchical Clustering to klassets_cluster object using stats::hclust — fit_hclust","text":"Fit Hierarchical Clustering klassets_cluster object using stats::hclust","code":""},{"path":"https://jkunst.com/klassets/reference/fit_hclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Hierarchical Clustering to klassets_cluster object using stats::hclust — fit_hclust","text":"","code":"fit_hclust(df, k = 3, method = \"complete\")"},{"path":"https://jkunst.com/klassets/reference/fit_hclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Hierarchical Clustering to klassets_cluster object using stats::hclust — fit_hclust","text":"df klassets_cluster object. k numeric determine number clusters. value passed stats::cutree method. method agglomeration method used.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_hclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Hierarchical Clustering to klassets_cluster object using stats::hclust — fit_hclust","text":"","code":"set.seed(12)  df <- sim_groups(n = 200, groups = 3)  plot(df)   dfhc <- fit_hclust(df, k = 4)  plot(dfhc)"},{"path":"https://jkunst.com/klassets/reference/fit_kmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit K-means to klassets_cluster object — fit_kmeans","title":"Fit K-means to klassets_cluster object — fit_kmeans","text":"Fit K-means klassets_cluster object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_kmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit K-means to klassets_cluster object — fit_kmeans","text":"","code":"fit_kmeans(df, centers = 3, ...)"},{"path":"https://jkunst.com/klassets/reference/fit_kmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit K-means to klassets_cluster object — fit_kmeans","text":"df klassets_cluster object. object sim_groups. centers numeric value pass kmeans_iterations function famous k parameter. ... Extra parameters kmeans_iterations function.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_kmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit K-means to klassets_cluster object — fit_kmeans","text":"","code":"set.seed(12)  df <- sim_groups(n = 200, groups = 3)  plot(df)   set.seed(124)  dfc <- fit_kmeans(df, centers = 4, max_iterations = 6)  plot(dfc)"},{"path":"https://jkunst.com/klassets/reference/fit_knn.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit K Nearest Neighbours to klassets_response_xy object — fit_knn","title":"Fit K Nearest Neighbours to klassets_response_xy object — fit_knn","text":"Fit K Nearest Neighbours klassets_response_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_knn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit K Nearest Neighbours to klassets_response_xy object — fit_knn","text":"","code":"fit_knn(df, neighbours = 10, type = \"prob\")"},{"path":"https://jkunst.com/klassets/reference/fit_knn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit K Nearest Neighbours to klassets_response_xy object — fit_knn","text":"df object sim_response_xy. neighbours neighbours parameter. type Type prediction, one prob response.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_knn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit K Nearest Neighbours to klassets_response_xy object — fit_knn","text":"","code":"set.seed(123)  df <- sim_response_xy(relationship = function(x, y) x**2 > sin(y))  plot(df)   # defaults to prob fit_knn(df) #> # A tibble: 500 × 4 #>    response       x        y prediction #>    <fct>      <dbl>    <dbl>      <dbl> #>  1 TRUE     -0.425  -0.293          0.7 #>  2 TRUE      0.577  -0.267          0.7 #>  3 FALSE    -0.182  -0.426          0.6 #>  4 TRUE      0.766  -0.840          0.8 #>  5 TRUE      0.881  -0.269          0.7 #>  6 TRUE     -0.909  -0.644          0.8 #>  7 FALSE     0.0562  0.0721         0.5 #>  8 TRUE      0.785   0.00790        0.7 #>  9 TRUE      0.103   0.890          0.5 #> 10 TRUE     -0.0868 -0.317          0.8 #> # … with 490 more rows  fit_knn(df, type = \"response\") #> # A tibble: 500 × 4 #>    response       x        y prediction #>    <fct>      <dbl>    <dbl> <fct>      #>  1 TRUE     -0.425  -0.293   TRUE       #>  2 TRUE      0.577  -0.267   TRUE       #>  3 FALSE    -0.182  -0.426   TRUE       #>  4 TRUE      0.766  -0.840   TRUE       #>  5 TRUE      0.881  -0.269   TRUE       #>  6 TRUE     -0.909  -0.644   TRUE       #>  7 FALSE     0.0562  0.0721  FALSE      #>  8 TRUE      0.785   0.00790 TRUE       #>  9 TRUE      0.103   0.890   TRUE       #> 10 TRUE     -0.0868 -0.317   TRUE       #> # … with 490 more rows  plot(fit_knn(df))   plot(fit_knn(df, neighbours = 3))   plot(fit_knn(df, neighbours = 10))   plot(fit_knn(df, neighbours = 200))   plot(fit_knn(df, neighbours = 3, type = \"response\"))   plot(fit_knn(df, neighbours = 10, type = \"response\"))   plot(fit_knn(df, neighbours = 200, type = \"response\"))"},{"path":"https://jkunst.com/klassets/reference/fit_linear_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Linear model to klassets_xy object — fit_linear_model","title":"Fit Linear model to klassets_xy object — fit_linear_model","text":"Fit Linear model klassets_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_linear_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Linear model to klassets_xy object — fit_linear_model","text":"","code":"fit_linear_model(df, order = 1, stepwise = FALSE, verbose = FALSE)"},{"path":"https://jkunst.com/klassets/reference/fit_linear_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Linear model to klassets_xy object — fit_linear_model","text":"df object sim_response_xy. order Order predictive variable x. stepwise logical value indicate perform stepwise. verbose logical value indicate show trace stepwise procedure.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_linear_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Linear model to klassets_xy object — fit_linear_model","text":"","code":"df <- sim_xy()  df #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  1.97  3.23 #>  2  2.08  3.82 #>  3  2.31  4.10 #>  4  2.49  4.42 #>  5  2.50  4.65 #>  6  2.60  4.04 #>  7  2.77  4.93 #>  8  2.88  4.25 #>  9  2.96  3.73 #> 10  2.98  4.85 #> # … with 490 more rows  dflm <- fit_linear_model(df)  dflm #> # A tibble: 500 × 3 #>        x     y prediction #>    <dbl> <dbl>      <dbl> #>  1  1.97  3.23       4.02 #>  2  2.08  3.82       4.07 #>  3  2.31  4.10       4.18 #>  4  2.49  4.42       4.27 #>  5  2.50  4.65       4.28 #>  6  2.60  4.04       4.32 #>  7  2.77  4.93       4.41 #>  8  2.88  4.25       4.46 #>  9  2.96  3.73       4.51 #> 10  2.98  4.85       4.52 #> # … with 490 more rows  plot(dflm)   df <- sim_xy(n = 1000, x_dist = runif) df <- dplyr::mutate(df, y = y + 2*sin(5 * x)) plot(df)   plot(fit_linear_model(df))   plot(fit_linear_model(df, order = 5, stepwise = TRUE, verbose = TRUE)) #> Start:  AIC=-1331.12 #> y ~ x + x_2 + x_3 + x_4 + x_5 #>  #>        Df Sum of Sq    RSS     AIC #> <none>              261.03 -1331.1 #> - x_2   1    1.3189 262.35 -1328.1 #> - x_5   1    2.6237 263.65 -1323.1 #> - x     1    3.1489 264.18 -1321.1 #> - x_4   1    4.1460 265.18 -1317.4 #> - x_3   1    4.5131 265.54 -1316.0"},{"path":"https://jkunst.com/klassets/reference/fit_linear_model_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Linear Model tree to klassets_xy object — fit_linear_model_tree","title":"Fit Linear Model tree to klassets_xy object — fit_linear_model_tree","text":"Fit Linear Model tree klassets_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_linear_model_tree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Linear Model tree to klassets_xy object — fit_linear_model_tree","text":"","code":"fit_linear_model_tree(df, maxdepth = Inf, alpha = 0.05, ...)"},{"path":"https://jkunst.com/klassets/reference/fit_linear_model_tree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Linear Model tree to klassets_xy object — fit_linear_model_tree","text":"df object sim_response_xy. maxdepth Max depth tree. used partykit::mob_control. alpha Alpha value, used partykit::mob_control ... Addiotional options passed partykit::mob_control.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_linear_model_tree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Linear Model tree to klassets_xy object — fit_linear_model_tree","text":"","code":"df <- sim_xy()  df #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.36  3.80 #>  2  2.41  3.60 #>  3  2.43  3.79 #>  4  2.56  4.61 #>  5  2.57  4.38 #>  6  2.58  3.27 #>  7  2.71  3.27 #>  8  2.76  4.18 #>  9  2.78  3.95 #> 10  2.82  4.43 #> # … with 490 more rows  dflm <- fit_linear_model_tree(df)  dflm #> # A tibble: 500 × 3 #>        x     y prediction #>    <dbl> <dbl>      <dbl> #>  1  2.36  3.80       4.18 #>  2  2.41  3.60       4.20 #>  3  2.43  3.79       4.21 #>  4  2.56  4.61       4.28 #>  5  2.57  4.38       4.28 #>  6  2.58  3.27       4.29 #>  7  2.71  3.27       4.35 #>  8  2.76  4.18       4.37 #>  9  2.78  3.95       4.38 #> 10  2.82  4.43       4.41 #> # … with 490 more rows  plot(dflm)   df <- sim_xy(n = 1000, x_dist = runif) df <- dplyr::mutate(df, y = y + 2*sin(5 * x)) plot(df)   plot(fit_linear_model_tree(df))"},{"path":"https://jkunst.com/klassets/reference/fit_loess.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Local polynomial regression to klassets_xy object — fit_loess","title":"Fit Local polynomial regression to klassets_xy object — fit_loess","text":"Fit Local polynomial regression klassets_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_loess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Local polynomial regression to klassets_xy object — fit_loess","text":"","code":"fit_loess(df, ...)"},{"path":"https://jkunst.com/klassets/reference/fit_loess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Local polynomial regression to klassets_xy object — fit_loess","text":"df object sim_xy. ... Options stats::loess.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_loess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Local polynomial regression to klassets_xy object — fit_loess","text":"","code":"df <- sim_xy()  df #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.36  3.73 #>  2  2.43  4.47 #>  3  2.48  3.23 #>  4  2.68  4.38 #>  5  2.77  4.36 #>  6  2.85  4.17 #>  7  2.86  3.64 #>  8  2.88  3.47 #>  9  2.95  4.40 #> 10  2.99  3.60 #> # … with 490 more rows  dfloess <- fit_loess(df)  dfloess #> # A tibble: 500 × 3 #>        x     y prediction #>    <dbl> <dbl>      <dbl> #>  1  2.36  3.73       3.72 #>  2  2.43  4.47       3.80 #>  3  2.48  3.23       3.85 #>  4  2.68  4.38       4.05 #>  5  2.77  4.36       4.14 #>  6  2.85  4.17       4.21 #>  7  2.86  3.64       4.22 #>  8  2.88  3.47       4.24 #>  9  2.95  4.40       4.30 #> 10  2.99  3.60       4.34 #> # … with 490 more rows  plot(dfloess) #> Warning: Removed 9 row(s) containing missing values (geom_path).   df <- sim_xy(n = 1000, x_dist = runif) df <- dplyr::mutate(df, y = y + 2*sin(5 * x)) plot(df)   plot(fit_loess(df)) #> Warning: Removed 2 row(s) containing missing values (geom_path)."},{"path":"https://jkunst.com/klassets/reference/fit_logistic_regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Logistic regression to klassets_response_xy object — fit_logistic_regression","title":"Fit Logistic regression to klassets_response_xy object — fit_logistic_regression","text":"Fit Logistic regression klassets_response_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_logistic_regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Logistic regression to klassets_response_xy object — fit_logistic_regression","text":"","code":"fit_logistic_regression(df, order = 1, stepwise = FALSE, verbose = FALSE)"},{"path":"https://jkunst.com/klassets/reference/fit_logistic_regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Logistic regression to klassets_response_xy object — fit_logistic_regression","text":"df object sim_response_xy. order Order values x y. stepwise logical value indicate perform stepwise. verbose logical value indicate show trace stepwise procedure.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_logistic_regression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Logistic regression to klassets_response_xy object — fit_logistic_regression","text":"","code":"set.seed(123)  df <- sim_response_xy(n = 500, relationship = function(x, y) x**2 > y)  plot(df)   df_reg_log <- fit_logistic_regression(df)  plot(df_reg_log)   df_reg_log_3 <- fit_logistic_regression(df, order = 3, stepwise = TRUE)  plot(df_reg_log_3)"},{"path":"https://jkunst.com/klassets/reference/fit_mars.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Multivariate Adaptive Regression Splines to klassets_xy object — fit_mars","title":"Fit Multivariate Adaptive Regression Splines to klassets_xy object — fit_mars","text":"Fit Multivariate Adaptive Regression Splines klassets_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_mars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Multivariate Adaptive Regression Splines to klassets_xy object — fit_mars","text":"","code":"fit_mars(df, ...)"},{"path":"https://jkunst.com/klassets/reference/fit_mars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Multivariate Adaptive Regression Splines to klassets_xy object — fit_mars","text":"df object sim_xy. ... Options earth ::earth.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_mars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Multivariate Adaptive Regression Splines to klassets_xy object — fit_mars","text":"","code":"df <- sim_xy()  df #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.45  4.75 #>  2  2.49  4.56 #>  3  2.62  4.53 #>  4  2.80  4.59 #>  5  2.83  5.06 #>  6  2.84  3.92 #>  7  2.89  3.89 #>  8  2.96  4.78 #>  9  2.98  4.43 #> 10  2.99  4.53 #> # … with 490 more rows  dfmars <- fit_mars(df)  dfmars #> # A tibble: 500 × 3 #>        x     y prediction #>    <dbl> <dbl>      <dbl> #>  1  2.45  4.75       4.75 #>  2  2.49  4.56       4.75 #>  3  2.62  4.53       4.75 #>  4  2.80  4.59       4.75 #>  5  2.83  5.06       4.75 #>  6  2.84  3.92       4.75 #>  7  2.89  3.89       4.75 #>  8  2.96  4.78       4.75 #>  9  2.98  4.43       4.75 #> 10  2.99  4.53       4.75 #> # … with 490 more rows  plot(dfmars)   df <- sim_xy(n = 1000, x_dist = runif) df <- dplyr::mutate(df, y = y + 2*sin(5 * x)) plot(df)   plot(fit_mars(df))"},{"path":"https://jkunst.com/klassets/reference/fit_regression_random_forest.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit regression random forest to klassets_xy object — fit_regression_random_forest","title":"Fit regression random forest to klassets_xy object — fit_regression_random_forest","text":"Fit regression random forest klassets_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_regression_random_forest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit regression random forest to klassets_xy object — fit_regression_random_forest","text":"","code":"fit_regression_random_forest(   df,   ntree = 500L,   maxdepth = Inf,   trace = FALSE,   ... )"},{"path":"https://jkunst.com/klassets/reference/fit_regression_random_forest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit regression random forest to klassets_xy object — fit_regression_random_forest","text":"df object sim_xy. ntree Number trees grow forest. maxdepth Max depth trees. trace logical indicating progress bar shall printed forest grows. ... Options ranger::ranger.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_regression_random_forest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit regression random forest to klassets_xy object — fit_regression_random_forest","text":"","code":"df <- sim_xy()  df #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  1.87  3.22 #>  2  2.16  4.59 #>  3  2.32  4.50 #>  4  2.34  4.02 #>  5  2.39  4.19 #>  6  2.61  4.55 #>  7  2.68  4.67 #>  8  2.78  3.53 #>  9  2.80  5.13 #> 10  2.94  3.77 #> # … with 490 more rows  dfrrf <- fit_regression_random_forest(df)  dfrrf #> # A tibble: 500 × 3 #>        x     y prediction #>    <dbl> <dbl>      <dbl> #>  1  1.87  3.22       3.71 #>  2  2.16  4.59       4.39 #>  3  2.32  4.50       4.38 #>  4  2.34  4.02       4.30 #>  5  2.39  4.19       4.30 #>  6  2.61  4.55       4.49 #>  7  2.68  4.67       4.49 #>  8  2.78  3.53       4.09 #>  9  2.80  5.13       4.61 #> 10  2.94  3.77       3.85 #> # … with 490 more rows  plot(dfrrf)   df <- sim_xy(n = 1000, x_dist = runif) df <- dplyr::mutate(df, y = y + 2*sin(5 * x)) plot(df)   plot(fit_regression_random_forest(df))  plot(fit_regression_random_forest(df, ntree = 100, maxdepth = 3))"},{"path":"https://jkunst.com/klassets/reference/fit_regression_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit regression tree to klassets_xy object — fit_regression_tree","title":"Fit regression tree to klassets_xy object — fit_regression_tree","text":"Fit regression tree klassets_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_regression_tree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit regression tree to klassets_xy object — fit_regression_tree","text":"","code":"fit_regression_tree(df, maxdepth = Inf, alpha = 0.05, ...)"},{"path":"https://jkunst.com/klassets/reference/fit_regression_tree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit regression tree to klassets_xy object — fit_regression_tree","text":"df object sim_response_xy. maxdepth Max depth tree. used partykit::ctree_control. alpha Alpha value, used partykit::ctree_control ... Options partykit::ctree_control.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_regression_tree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit regression tree to klassets_xy object — fit_regression_tree","text":"","code":"df <- sim_xy()  df #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  1.85  4.55 #>  2  2.06  3.94 #>  3  2.18  4.24 #>  4  2.69  3.51 #>  5  2.70  4.42 #>  6  2.71  5.01 #>  7  2.74  4.19 #>  8  2.77  3.95 #>  9  2.86  5.40 #> 10  2.99  4.86 #> # … with 490 more rows  dflm <- fit_regression_tree(df)  dflm #> # A tibble: 500 × 3 #>        x     y prediction #>    <dbl> <dbl>      <dbl> #>  1  1.85  4.55       4.60 #>  2  2.06  3.94       4.60 #>  3  2.18  4.24       4.60 #>  4  2.69  3.51       4.60 #>  5  2.70  4.42       4.60 #>  6  2.71  5.01       4.60 #>  7  2.74  4.19       4.60 #>  8  2.77  3.95       4.60 #>  9  2.86  5.40       4.60 #> 10  2.99  4.86       4.60 #> # … with 490 more rows  plot(dflm)   df <- sim_xy(n = 1000, x_dist = runif) df <- dplyr::mutate(df, y = y + 2*sin(5 * x)) plot(df)   plot(fit_regression_tree(df, maxdepth = 3))   # default plot(fit_regression_tree(df))"},{"path":"https://jkunst.com/klassets/reference/fit_statskmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit K-means to klassets_cluster object using stats::kmeans — fit_statskmeans","title":"Fit K-means to klassets_cluster object using stats::kmeans — fit_statskmeans","text":"Fit K-means klassets_cluster object using stats::kmeans","code":""},{"path":"https://jkunst.com/klassets/reference/fit_statskmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit K-means to klassets_cluster object using stats::kmeans — fit_statskmeans","text":"","code":"fit_statskmeans(df, centers = 3, ...)"},{"path":"https://jkunst.com/klassets/reference/fit_statskmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit K-means to klassets_cluster object using stats::kmeans — fit_statskmeans","text":"df klassets_cluster object. centers numeric value pass stats::kmeans method. famous k parameter. ... Extra parameter stats::kmeans function.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_statskmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit K-means to klassets_cluster object using stats::kmeans — fit_statskmeans","text":"","code":"set.seed(12)  df <- sim_groups(n = 200, groups = 3)  plot(df)   dfc <- fit_statskmeans(df, centers = 4)  plot(dfc)"},{"path":"https://jkunst.com/klassets/reference/kmeans_iterations.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate intermediate iterations when performing K-means — kmeans_iterations","title":"Generate intermediate iterations when performing K-means — kmeans_iterations","text":"Generate intermediate iterations performing K-means","code":""},{"path":"https://jkunst.com/klassets/reference/kmeans_iterations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate intermediate iterations when performing K-means — kmeans_iterations","text":"","code":"kmeans_iterations(   df,   centers = 3,   tolerance = 1e-05,   max_iterations = 15,   verbose = FALSE )"},{"path":"https://jkunst.com/klassets/reference/kmeans_iterations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate intermediate iterations when performing K-means — kmeans_iterations","text":"df object sim_groups. centers many clusters. tolerance value indicating early stop. max_iterations Max iterations calculate. verbose logical value, show iterations messages.","code":""},{"path":"https://jkunst.com/klassets/reference/kmeans_iterations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate intermediate iterations when performing K-means — kmeans_iterations","text":"","code":"set.seed(12)  df <- sim_groups(n = 200, groups = 3)  plot(df)   set.seed(124)  kmi <- kmeans_iterations(df, centers = 4, max_iterations = 6)  plot(kmi)"},{"path":"https://jkunst.com/klassets/reference/mnist_plot_digits.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot some digits from train mnist data — mnist_plot_digits","title":"Plot some digits from train mnist data — mnist_plot_digits","text":"Plot digits train mnist data","code":""},{"path":"https://jkunst.com/klassets/reference/mnist_plot_digits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot some digits from train mnist data — mnist_plot_digits","text":"","code":"mnist_plot_digits(ids = NULL)"},{"path":"https://jkunst.com/klassets/reference/mnist_plot_digits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot some digits from train mnist data — mnist_plot_digits","text":"ids Rows show.","code":""},{"path":"https://jkunst.com/klassets/reference/mnist_plot_digits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot some digits from train mnist data — mnist_plot_digits","text":"","code":"mnist_plot_digits(1)   mnist_plot_digits(c(10, 20, 40, 22))   set.seed(123)  mnist_plot_digits(sample(seq(60000), size = 16))"},{"path":"https://jkunst.com/klassets/reference/mnist_test.html","id":null,"dir":"Reference","previous_headings":"","what":"MNIST test data — mnist_test","title":"MNIST test data — mnist_test","text":"Original source    http://yann.lecun.com/exdb/mnist/ Converted csv   https://pjreddie.com/projects/mnist--csv/ Downloaded    https://www.kaggle.com/datasets/oddrationale/mnist--csv","code":""},{"path":"https://jkunst.com/klassets/reference/mnist_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MNIST test data — mnist_test","text":"","code":"mnist_test"},{"path":"https://jkunst.com/klassets/reference/mnist_test.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"MNIST test data — mnist_test","text":"data frame 60000 rows 785 variables.","code":""},{"path":"https://jkunst.com/klassets/reference/mnist_test.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"MNIST test data — mnist_test","text":"http://yann.lecun.com/exdb/mnist/","code":""},{"path":"https://jkunst.com/klassets/reference/mnist_train.html","id":null,"dir":"Reference","previous_headings":"","what":"MNIST train data — mnist_train","title":"MNIST train data — mnist_train","text":"Original source    http://yann.lecun.com/exdb/mnist/ Converted csv   https://pjreddie.com/projects/mnist--csv/ Downloaded    https://www.kaggle.com/datasets/oddrationale/mnist--csv","code":""},{"path":"https://jkunst.com/klassets/reference/mnist_train.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MNIST train data — mnist_train","text":"","code":"mnist_train"},{"path":"https://jkunst.com/klassets/reference/mnist_train.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"MNIST train data — mnist_train","text":"data frame 60000 rows 785 variables.","code":""},{"path":"https://jkunst.com/klassets/reference/mnist_train.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"MNIST train data — mnist_train","text":"http://yann.lecun.com/exdb/mnist/","code":""},{"path":"https://jkunst.com/klassets/reference/sim_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate data sets to apply clustering algorithms — sim_groups","title":"Generate data sets to apply clustering algorithms — sim_groups","text":"Generate data sets apply clustering algorithms","code":""},{"path":"https://jkunst.com/klassets/reference/sim_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate data sets to apply clustering algorithms — sim_groups","text":"","code":"sim_groups(n = 500, groups = 3, props = NULL)"},{"path":"https://jkunst.com/klassets/reference/sim_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate data sets to apply clustering algorithms — sim_groups","text":"n integer. groups integer props vector probabilities length groups.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_groups.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate data sets to apply clustering algorithms — sim_groups","text":"","code":"set.seed(123456)  df <- sim_groups()  df #> # A tibble: 500 × 3 #>    group     x     y #>    <chr> <dbl> <dbl> #>  1 1     0.729 -6.29 #>  2 1     1.19  -8.28 #>  3 1     0.915 -7.91 #>  4 1     1.22  -7.68 #>  5 1     1.07  -8.88 #>  6 1     0.117 -7.74 #>  7 1     1.59  -7.53 #>  8 1     1.62  -7.17 #>  9 1     0.108 -8.65 #> 10 1     0.333 -9.10 #> # … with 490 more rows  plot(df)   plot(sim_groups(500, 5))"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_1.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate quasi Anscombe data sets Type 1 — sim_quasianscombe_set_1","title":"Generate quasi Anscombe data sets Type 1 — sim_quasianscombe_set_1","text":"function generate data set Type 1  creating first x random vector apply linear transformation using beta0 beta1 finally adding normal distributed noise using error_sd creating y values.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate quasi Anscombe data sets Type 1 — sim_quasianscombe_set_1","text":"","code":"sim_quasianscombe_set_1(   n = 500,   beta0 = 3,   beta1 = 0.5,   x_dist = purrr::partial(rnorm, mean = 5, sd = 1),   error_dist = purrr::partial(rnorm, sd = 0.5) )"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate quasi Anscombe data sets Type 1 — sim_quasianscombe_set_1","text":"n Number observations beta0 beta0, default value: 3, beta1 beta1, default value: 0.5 x_dist random number generation function. Default rnorm mean 5 sd 1. error_dist random number generation function. Default rnorm mean 0 sd 0.5.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate quasi Anscombe data sets Type 1 — sim_quasianscombe_set_1","text":"typical first example regression analysis taught. Internally procedure sim_xy.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate quasi Anscombe data sets Type 1 — sim_quasianscombe_set_1","text":"","code":"df <- sim_quasianscombe_set_1()  df #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.22  3.65 #>  2  2.29  4.97 #>  3  2.60  3.40 #>  4  2.76  4.51 #>  5  2.83  3.95 #>  6  3.05  3.83 #>  7  3.07  5.01 #>  8  3.07  4.90 #>  9  3.14  4.61 #> 10  3.15  4.76 #> # … with 490 more rows  plot(df)   plot(df, add_lm = FALSE)   plot(sim_quasianscombe_set_1(n = 1000))   plot(sim_quasianscombe_set_1(n = 1000, beta0 = 0, beta1 = 1, x_dist = runif))"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_2.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate quasi Anscombe data sets Type 2: No linear relationship — sim_quasianscombe_set_2","title":"Generate quasi Anscombe data sets Type 2: No linear relationship — sim_quasianscombe_set_2","text":"Data sets Type 2 shows linear realtionship x y can lead regression model (terms parameter values) Type 1.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate quasi Anscombe data sets Type 2: No linear relationship — sim_quasianscombe_set_2","text":"","code":"sim_quasianscombe_set_2(   df,   fun = function(x) {      x^2  },   residual_factor = 0.25 )"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate quasi Anscombe data sets Type 2: No linear relationship — sim_quasianscombe_set_2","text":"df data frame sim_quasianscombe_set_1 (similar). fun function apply, applied normalized version x. residual_factor Numeric value multiply residual modify variance.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate quasi Anscombe data sets Type 2: No linear relationship — sim_quasianscombe_set_2","text":"","code":"df <- sim_quasianscombe_set_1()  dataset2 <- sim_quasianscombe_set_2(df)  dataset2 #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  1.84 14.1  #>  2  2.08 12.4  #>  3  2.10 12.0  #>  4  2.21 11.3  #>  5  2.49 10.0  #>  6  2.67  9.09 #>  7  2.96  7.95 #>  8  3.04  7.47 #>  9  3.10  7.50 #> 10  3.11  7.19 #> # … with 490 more rows  plot(dataset2)   plot(sim_quasianscombe_set_2(df, residual_factor = 0))   fun1 <- function(x){ 2 * sin(x*diff(range(x))) }  plot(sim_quasianscombe_set_2(df, fun = fun1))   fun2 <- abs  plot(sim_quasianscombe_set_2(df, fun = fun2))   fun3 <- function(x){ (x - mean(x)) * sin(x*diff(range(x))) }  plot(sim_quasianscombe_set_2(df, fun = fun3))"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_3.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate quasi Anscombe data sets Type 3: Extreme values (a.k.a Outliers) — sim_quasianscombe_set_3","title":"Generate quasi Anscombe data sets Type 3: Extreme values (a.k.a Outliers) — sim_quasianscombe_set_3","text":"Data sets Type 3 get outliers conserving $x$ mean coefficients -different significance- adjusted linear model.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate quasi Anscombe data sets Type 3: Extreme values (a.k.a Outliers) — sim_quasianscombe_set_3","text":"","code":"sim_quasianscombe_set_3(   df,   prop = 0.05,   beta1_factor = 0.5,   residual_factor = 0.25 )"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate quasi Anscombe data sets Type 3: Extreme values (a.k.a Outliers) — sim_quasianscombe_set_3","text":"df data frame sim_quasianscombe_set_1 (similar). prop proportion value modify outliers. beta1_factor Numeric value modify beta1 value. residual_factor Numeric value multiply residual modify variance.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_3.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate quasi Anscombe data sets Type 3: Extreme values (a.k.a Outliers) — sim_quasianscombe_set_3","text":"function : Calculate linear regression model calculate new trend using 0.5 times beta1 Take prop% values greater 2*prop x values modify related y value get original estimation beta1 Apply residual_factor factor residual get minor variance better visual impression outliers effect.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_3.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate quasi Anscombe data sets Type 3: Extreme values (a.k.a Outliers) — sim_quasianscombe_set_3","text":"","code":"df <- sim_quasianscombe_set_1()  dataset3 <- sim_quasianscombe_set_3(df)  dataset3 #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.17  4.36 #>  2  2.26  4.70 #>  3  2.37  4.81 #>  4  2.39  4.86 #>  5  2.41  4.81 #>  6  2.46  4.62 #>  7  2.59  4.75 #>  8  2.66  4.78 #>  9  2.68  4.64 #> 10  2.83  4.67 #> # … with 490 more rows  plot(dataset3)   plot(sim_quasianscombe_set_3(df, prop = 0.1, residual_factor = 0))"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_4.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate quasi Anscombe data sets Type 4: 2 Clusters — sim_quasianscombe_set_4","title":"Generate quasi Anscombe data sets Type 4: 2 Clusters — sim_quasianscombe_set_4","text":"Data sets Type 4 recreate two cluster keeping coefficient original regression model.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_4.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate quasi Anscombe data sets Type 4: 2 Clusters — sim_quasianscombe_set_4","text":"","code":"sim_quasianscombe_set_4(df, rescale_to = c(0.1, 0.2), prop = 0.15)"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_4.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate quasi Anscombe data sets Type 4: 2 Clusters — sim_quasianscombe_set_4","text":"df data frame sim_quasianscombe_set_1 (similar). rescale_to Rescale x value create second cluster. prop proportion value modify second group/cluster.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_4.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate quasi Anscombe data sets Type 4: 2 Clusters — sim_quasianscombe_set_4","text":"function : Disorder order x values. Rescale x value specific original quantiles. take proportion value translate left keeping original mean x. Finally add value associated y value subtract complement group regression model terms coefficients.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_4.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate quasi Anscombe data sets Type 4: 2 Clusters — sim_quasianscombe_set_4","text":"","code":"df <- sim_quasianscombe_set_1()  dataset4 <- sim_quasianscombe_set_4(df)  dataset4 #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  3.70  5.88 #>  2  3.72  4.39 #>  3  3.72  5.07 #>  4  3.73  4.49 #>  5  3.74  5.41 #>  6  3.74  5.00 #>  7  3.75  4.02 #>  8  3.75  5.12 #>  9  3.75  3.99 #> 10  3.75  4.62 #> # … with 490 more rows  plot(dataset4)   plot(sim_quasianscombe_set_4(df, rescale_to = c(0, .1), prop = 0.5))"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_5.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate quasi Anscombe data sets Type 5: Heteroskedasticity — sim_quasianscombe_set_5","title":"Generate quasi Anscombe data sets Type 5: Heteroskedasticity — sim_quasianscombe_set_5","text":"Data sets Type 5 recreates phenomenon heteroskedasticity residuals.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_5.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate quasi Anscombe data sets Type 5: Heteroskedasticity — sim_quasianscombe_set_5","text":"","code":"sim_quasianscombe_set_5(df, fun = identity, residual_factor = 10)"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_5.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate quasi Anscombe data sets Type 5: Heteroskedasticity — sim_quasianscombe_set_5","text":"df data frame sim_quasianscombe_set_1 (similar). fun function apply index multiply residuals original model. residual_factor Numeric value multiply residual modify variance.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_5.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate quasi Anscombe data sets Type 5: Heteroskedasticity — sim_quasianscombe_set_5","text":"function take residuals $e_i$ get $e'_i = e_i * fun()$ rescale $e'_i$ range $e_i$.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_5.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate quasi Anscombe data sets Type 5: Heteroskedasticity — sim_quasianscombe_set_5","text":"","code":"df <- sim_quasianscombe_set_1()  dataset5 <- sim_quasianscombe_set_5(df)  dataset5 #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  1.25  3.61 #>  2  2.19  4.08 #>  3  2.40  4.20 #>  4  2.45  4.25 #>  5  2.57  4.25 #>  6  2.68  4.30 #>  7  2.70  4.32 #>  8  2.79  4.42 #>  9  2.97  4.60 #> 10  2.97  4.42 #> # … with 490 more rows  plot(dataset5)   plot(sim_quasianscombe_set_5(df, fun = rev))   plot(sim_quasianscombe_set_5(df, fun = sqrt))   plot(sim_quasianscombe_set_5(df, fun = log))   plot(sim_quasianscombe_set_5(df, fun = function(x) x^(1+0.6)))"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_6.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate quasi Anscombe data sets Type 6: Simpson's Paradox — sim_quasianscombe_set_6","title":"Generate quasi Anscombe data sets Type 6: Simpson's Paradox — sim_quasianscombe_set_6","text":"Data sets Type 6 recreates phenomenon Simpon's paradox.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_6.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate quasi Anscombe data sets Type 6: Simpson's Paradox — sim_quasianscombe_set_6","text":"","code":"sim_quasianscombe_set_6(df, groups = 3, b1_factor = -1, residual_factor = 0.25)"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_6.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate quasi Anscombe data sets Type 6: Simpson's Paradox — sim_quasianscombe_set_6","text":"df data frame sim_quasianscombe_set_1 (similar). groups Number groups separate x values. b1_factor numeric value get slope group $beta_1$. residual_factor Numeric value multiply residual modify variance.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_6.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate quasi Anscombe data sets Type 6: Simpson's Paradox — sim_quasianscombe_set_6","text":"function take x vector separate groups groups apply local model modified regression using b1_factor factor. residual multiply value 0 1 make visual effect greater.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_6.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate quasi Anscombe data sets Type 6: Simpson's Paradox — sim_quasianscombe_set_6","text":"","code":"df <- sim_quasianscombe_set_1()  dataset6 <- sim_quasianscombe_set_6(df)  dataset6 #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.24  5.51 #>  2  2.66  5.38 #>  3  2.71  5.49 #>  4  2.83  5.27 #>  5  2.90  5.15 #>  6  2.92  5.02 #>  7  2.95  5.12 #>  8  2.96  5.26 #>  9  2.96  5.13 #> 10  2.96  5.12 #> # … with 490 more rows  plot(dataset6)"},{"path":"https://jkunst.com/klassets/reference/sim_response_xy.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate data sets to apply binary classifiers — sim_response_xy","title":"Generate data sets to apply binary classifiers — sim_response_xy","text":"Generate data sets apply binary classifiers","code":""},{"path":"https://jkunst.com/klassets/reference/sim_response_xy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate data sets to apply binary classifiers — sim_response_xy","text":"","code":"sim_response_xy(   n = 500,   x_dist = purrr::partial(runif, min = -1, max = 1),   y_dist = x_dist,   relationship = function(x, y) x > y,   noise = 0.2 )"},{"path":"https://jkunst.com/klassets/reference/sim_response_xy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate data sets to apply binary classifiers — sim_response_xy","text":"n intenger x_dist random number generation function. y_dist random number generation function. relationship function specify relationship x, y response. function f(x, y) need return logical value. noise number 0 1.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_response_xy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate data sets to apply binary classifiers — sim_response_xy","text":"","code":"set.seed(123)  df <- sim_response_xy(n = 500)  df #> # A tibble: 500 × 3 #>    response       x        y #>    <fct>      <dbl>    <dbl> #>  1 FALSE    -0.425  -0.293   #>  2 TRUE      0.577  -0.267   #>  3 FALSE    -0.182  -0.426   #>  4 TRUE      0.766  -0.840   #>  5 TRUE      0.881  -0.269   #>  6 FALSE    -0.909  -0.644   #>  7 FALSE     0.0562  0.0721  #>  8 TRUE      0.785   0.00790 #>  9 TRUE      0.103   0.890   #> 10 TRUE     -0.0868 -0.317   #> # … with 490 more rows  plot(df)"},{"path":"https://jkunst.com/klassets/reference/sim_xy.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate data sets to apply regression methods — sim_xy","title":"Generate data sets to apply regression methods — sim_xy","text":"Generate data sets apply regression methods","code":""},{"path":"https://jkunst.com/klassets/reference/sim_xy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate data sets to apply regression methods — sim_xy","text":"","code":"sim_xy(   n = 500,   beta0 = 3,   beta1 = 0.5,   x_dist = purrr::partial(rnorm, mean = 5, sd = 1),   error_dist = purrr::partial(rnorm, sd = 0.5) )"},{"path":"https://jkunst.com/klassets/reference/sim_xy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate data sets to apply regression methods — sim_xy","text":"n Number observations beta0 beta0, default value: 3, beta1 beta1, default value: 0.5 x_dist random number generation function. Default rnorm mean 5 sd 1. error_dist random number generation function. Default rnorm mean 0 sd 0.5.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_xy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate data sets to apply regression methods — sim_xy","text":"","code":"df <- sim_xy()  df #> # A tibble: 500 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.45  4.75 #>  2  2.49  4.56 #>  3  2.62  4.53 #>  4  2.80  4.59 #>  5  2.83  5.06 #>  6  2.84  3.92 #>  7  2.89  3.89 #>  8  2.96  4.78 #>  9  2.98  4.43 #> 10  2.99  4.53 #> # … with 490 more rows  plot(df)   klassets:::plot.klassets_xy(setNames(cars, c(\"x\", \"y\")))"}]
