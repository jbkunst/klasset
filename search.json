[{"path":"https://jkunst.com/klassets/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 klassets authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jkunst.com/klassets/articles/Binary-classification.html","id":"generating-data-set","dir":"Articles","previous_headings":"","what":"Generating data set","title":"Binary classification","text":"main function sim_response_xy, need define: number observations simulate. Distributions sample \\(x\\) \\(y\\). example purrr::partial(runif, min = -1, max = 1). function define relation response \\(x\\) \\(y\\), example function(x, y) x > y function must return logical value. number define noise generated data.","code":"library(klassets) library(ggplot2) library(patchwork)  set.seed(123)  df_default <- sim_response_xy(n = 500)  df_default #> # A tibble: 500 × 3 #>    response       x        y #>    <fct>      <dbl>    <dbl> #>  1 FALSE    -0.425  -0.293   #>  2 TRUE      0.577  -0.267   #>  3 FALSE    -0.182  -0.426   #>  4 TRUE      0.766  -0.840   #>  5 TRUE      0.881  -0.269   #>  6 FALSE    -0.909  -0.644   #>  7 FALSE     0.0562  0.0721  #>  8 TRUE      0.785   0.00790 #>  9 TRUE      0.103   0.890   #> 10 TRUE     -0.0868 -0.317   #> # … with 490 more rows  plot(df_default) df <- sim_response_xy(   n = 500,    x_dist = purrr::partial(runif, min = -1, max = 1),   # relationship = function(x, y) sqrt(abs(x)) - x - 0.5 > sin(y),   relationship = function(x, y) sin(x*pi) > sin(y*pi),   noise = 0.15   )  plot(df)"},{"path":[]},{"path":"https://jkunst.com/klassets/articles/Binary-classification.html","id":"logistic-regression","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Logistic Regression","title":"Binary classification","text":"default model use order = 1 variables, .e, response ~ x + y. can get better fit increase order.  Testing various orders.","code":"df_lr <- fit_logistic_regression(df)  df_lr #> # A tibble: 500 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl>      <dbl> #>  1 TRUE      0.876  -0.681       0.885 #>  2 TRUE      0.976  -0.711       0.899 #>  3 TRUE     -0.0874 -0.702       0.745 #>  4 FALSE    -0.539   0.0289      0.385 #>  5 TRUE      0.391  -0.0143      0.637 #>  6 FALSE     0.113   0.233       0.478 #>  7 TRUE      0.169  -0.105       0.614 #>  8 FALSE    -0.133  -0.889       0.785 #>  9 FALSE    -0.148  -0.989       0.807 #> 10 TRUE      0.194  -0.556       0.760 #> # … with 490 more rows  plot(df_lr) df_lr2 <- fit_logistic_regression(df, order = 4, stepwise = TRUE)  attr(df_lr2, \"model\") #>  #> Call:  glm(formula = response ~ x + y + x_3 + y_3, family = binomial,  #>     data = df) #>  #> Coefficients: #> (Intercept)            x            y          x_3          y_3   #>      0.1533       3.3121      -4.4480      -3.3786       4.6436   #>  #> Degrees of Freedom: 499 Total (i.e. Null);  495 Residual #> Null Deviance:       690.8  #> Residual Deviance: 518   AIC: 528  plot(df_lr2) orders <- c(1, 2, 3, 4)  orders |>    purrr::map(fit_logistic_regression, df = df) |>    purrr::map(plot) |>    purrr::reduce(`+`) +   patchwork::plot_layout(guides = \"collect\") &   theme_void() + theme(legend.position = \"none\")"},{"path":"https://jkunst.com/klassets/articles/Binary-classification.html","id":"classification-tree-partykitctree","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Classification Tree partykit::ctree","title":"Binary classification","text":"region filled probability respective node. can specify type prediction using type argument. case response.  now node.","code":"df_rt <- fit_classification_tree(df)  plot(df_rt) plot(fit_classification_tree(df, alpha = 0.25)) df_rt_response <- fit_classification_tree(df, type = \"response\")  df_rt_response #> # A tibble: 500 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl> <fct>      #>  1 TRUE      0.876  -0.681  TRUE       #>  2 TRUE      0.976  -0.711  TRUE       #>  3 TRUE     -0.0874 -0.702  TRUE       #>  4 FALSE    -0.539   0.0289 FALSE      #>  5 TRUE      0.391  -0.0143 TRUE       #>  6 FALSE     0.113   0.233  FALSE      #>  7 TRUE      0.169  -0.105  TRUE       #>  8 FALSE    -0.133  -0.889  TRUE       #>  9 FALSE    -0.148  -0.989  TRUE       #> 10 TRUE      0.194  -0.556  TRUE       #> # … with 490 more rows  plot(df_rt_response) df_rt_node <- fit_classification_tree(df, type = \"node\", maxdepth = 3)  df_rt_node #> # A tibble: 500 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl>      <int> #>  1 TRUE      0.876  -0.681           4 #>  2 TRUE      0.976  -0.711           4 #>  3 TRUE     -0.0874 -0.702           4 #>  4 FALSE    -0.539   0.0289          3 #>  5 TRUE      0.391  -0.0143          4 #>  6 FALSE     0.113   0.233           6 #>  7 TRUE      0.169  -0.105           4 #>  8 FALSE    -0.133  -0.889           4 #>  9 FALSE    -0.148  -0.989           4 #> 10 TRUE      0.194  -0.556           4 #> # … with 490 more rows  plot(df_rt_node) plot(attr(df_rt_node, \"model\"))"},{"path":"https://jkunst.com/klassets/articles/Binary-classification.html","id":"k-nearest-neighbours-classknn","dir":"Articles","previous_headings":"Fit classification algorithms","what":"K Nearest Neighbours class::knn","title":"Binary classification","text":"","code":"# defaults to prob fit_knn(df) #> # A tibble: 500 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl>      <dbl> #>  1 TRUE      0.876  -0.681         1   #>  2 TRUE      0.976  -0.711         1   #>  3 TRUE     -0.0874 -0.702         1   #>  4 FALSE    -0.539   0.0289        0.9 #>  5 TRUE      0.391  -0.0143        0.8 #>  6 FALSE     0.113   0.233         0.8 #>  7 TRUE      0.169  -0.105         0.9 #>  8 FALSE    -0.133  -0.889         0.8 #>  9 FALSE    -0.148  -0.989         0.6 #> 10 TRUE      0.194  -0.556         0.7 #> # … with 490 more rows  fit_knn(df, type = \"response\") #> # A tibble: 500 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl> <fct>      #>  1 TRUE      0.876  -0.681  TRUE       #>  2 TRUE      0.976  -0.711  TRUE       #>  3 TRUE     -0.0874 -0.702  TRUE       #>  4 FALSE    -0.539   0.0289 FALSE      #>  5 TRUE      0.391  -0.0143 TRUE       #>  6 FALSE     0.113   0.233  FALSE      #>  7 TRUE      0.169  -0.105  TRUE       #>  8 FALSE    -0.133  -0.889  TRUE       #>  9 FALSE    -0.148  -0.989  TRUE       #> 10 TRUE      0.194  -0.556  TRUE       #> # … with 490 more rows  plot(fit_knn(df)) neighbours <- c(3, 10, 50, 300)  purrr::map(neighbours, fit_knn, df = df) |>    purrr::map(plot) |>    purrr::reduce(`+`) +   patchwork::plot_layout(guides = \"collect\") &   theme_void() + theme(legend.position = \"none\") purrr::map(neighbours, fit_knn, df = df, type = \"response\") |>    purrr::map(plot) |>    purrr::reduce(`+`) +   patchwork::plot_layout(guides = \"collect\")  &   theme_void() + theme(legend.position = \"none\")"},{"path":"https://jkunst.com/klassets/articles/Clustering.html","id":"generating-data-set","dir":"Articles","previous_headings":"","what":"Generating data set","title":"Clustering","text":"main function sim_groups, need define: number observations draw. number groups sample. optional argument define proportion group.","code":"library(klassets)  set.seed(123)  df <- sim_groups(n = 500, groups = 3)  plot(df)"},{"path":[]},{"path":"https://jkunst.com/klassets/articles/Clustering.html","id":"k-means-statskmeans","dir":"Articles","previous_headings":"Fit cluster algorithms","what":"K-means stats::kmeans","title":"Clustering","text":"can apply stats::kmeans using fit_statskmeans_clust.","code":"dfc1 <- fit_statskmeans(df, centers = 2)  plot(dfc1)"},{"path":"https://jkunst.com/klassets/articles/Clustering.html","id":"hierarchical-clustering-statshclust","dir":"Articles","previous_headings":"Fit cluster algorithms","what":"Hierarchical Clustering stats::hclust","title":"Clustering","text":"","code":"dfhc <- fit_hclust(df, k = 2)  plot(dfhc)"},{"path":"https://jkunst.com/klassets/articles/Clustering.html","id":"k-means-basic-klassets-implementation","dir":"Articles","previous_headings":"Fit cluster algorithms","what":"K-means: Basic {klassets} implementation","title":"Clustering","text":"use basic K-means implementation :  benefit? second one use helper function kmeans_iterations keep iteration see algorithm converges.  Now can use gganimate package using object result kmeans_iterations due classification every point every step: can take output function data use gganimate make animation using klassets home page. code used animation can found package using:","code":"set.seed(234)  dfc2 <- fit_kmeans(df, centers = 2, max_iteration = 6)  plot(dfc2) set.seed(234)  kmi <- kmeans_iterations(df, centers = 2, max_iteration = 6)  plot(kmi) kmi #> $points #> # A tibble: 2,988 × 6 #>    iteration    id group      x     y cluster #>        <int> <int> <chr>  <dbl> <dbl> <fct>   #>  1         1     1 1      4.53   8.60 NA      #>  2         1     2 1      5.57   6.42 NA      #>  3         1     3 1      2.62   6.28 NA      #>  4         1     4 1      4.82   7.41 NA      #>  5         1     5 1      0.583  2.50 NA      #>  6         1     6 1     -5.49   8.30 NA      #>  7         1     7 1      3.59   9.44 NA      #>  8         1     8 1     -0.224  3.95 NA      #>  9         1     9 1     -2.62  10.7  NA      #> 10         1    10 1     -0.695  8.74 NA      #> # … with 2,978 more rows #>  #> $centers #> # A tibble: 12 × 4 #>    iteration cluster     cx    cy #>        <int> <fct>    <dbl> <dbl> #>  1         1 A       -4.67   5.85 #>  2         1 B        3.70  -7.21 #>  3         2 A        0.327  5.85 #>  4         2 B        7.26  -1.35 #>  5         3 A        0.170  5.29 #>  6         3 B        7.65  -1.30 #>  7         4 A        0.132  5.05 #>  8         4 B        7.83  -1.27 #>  9         5 A        0.137  4.76 #> 10         5 B        8.04  -1.24 #> 11         6 A        0.155  4.57 #> 12         6 B        8.19  -1.22 #>  #> attr(,\"class\") #> [1] \"klassets_kmiterations\" \"list\" system.file(\"animation_kmeans_iterations.R\", package = \"klassets\") #> [1] \"/home/runner/work/_temp/Library/klassets/animation_kmeans_iterations.R\""},{"path":[]},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"set-1-the-original","dir":"Articles","previous_headings":"The sets","what":"Set 1: The original","title":"Quasi Anscombe data sets","text":"","code":"library(klassets) library(ggplot2)  set.seed(123)  df <- sim_quasianscombe_set_1(n = 100, beta1 = 2)  plot(df) +   # xlim(0, NA) +   # ylim(0, NA) +   labs(subtitle = \"Original data set\")"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"set-4-no-linear-relationship","dir":"Articles","previous_headings":"The sets","what":"Set 4: No linear relationship","title":"Quasi Anscombe data sets","text":"","code":"func <- function(x) 1.5 * x^2  df2_1 <- sim_quasianscombe_set_2(df, residual_factor = 0, fun = func)  funktion <- function(x){ 2 * sin(x*diff(range(x))) }  df2_2 <- sim_quasianscombe_set_2(df, fun = funktion, residual_factor = 1.25)"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"set-3-extreme-values","dir":"Articles","previous_headings":"The sets","what":"Set 3: Extreme values","title":"Quasi Anscombe data sets","text":"","code":"df3_1 <- sim_quasianscombe_set_3(df, prop = 0.10)  df3_2 <- sim_quasianscombe_set_3(df, prop = 0.15, residual_factor = 0)"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"set-4-clusters","dir":"Articles","previous_headings":"The sets","what":"Set 4: Clusters","title":"Quasi Anscombe data sets","text":"","code":"df4_1 <- sim_quasianscombe_set_4(df, prop = 0.25)  df4_2 <- sim_quasianscombe_set_4(df, rescale_to = c(0, .1), prop = 0.5)"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"set-5-heteroskedasticity","dir":"Articles","previous_headings":"The sets","what":"Set 5: Heteroskedasticity","title":"Quasi Anscombe data sets","text":"","code":"df5_1 <- sim_quasianscombe_set_5(df, residual_factor = 2)  df5_2 <- sim_quasianscombe_set_5(df, fun = function(x) rev(x**2))"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"set-6-simpsons-paradox","dir":"Articles","previous_headings":"The sets","what":"Set 6: Simpson’s Paradox","title":"Quasi Anscombe data sets","text":"","code":"df6_1 <- sim_quasianscombe_set_6(df, residual_factor = 1)  df6_2 <- sim_quasianscombe_set_6(df, groups = 4, b1_factor = 0, residual_factor = 0.1)"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"combine-results","dir":"Articles","previous_headings":"","what":"Combine results","title":"Quasi Anscombe data sets","text":"[@warnes](https://github.com/warnes) gtools package","code":"library(dplyr, warn.conflicts = FALSE) library(tidyr) library(purrr) library(broom)  dfs <- list(   \"Original\" = df,   \"Set 2 v1\" = df2_1,   \"Set 2 v2\" = df2_2,   \"Set 3 v1\" = df3_1,   \"Set 3 v2\" = df3_2,   \"Set 4 v1\" = df4_1,   \"Set 4 v2\" = df4_2,   \"Set 5 v1\" = df5_1,   \"Set 5 v2\" = df5_2,   \"Set 6 v1\" = df6_1,   \"Set 6 v2\" = df6_2 )  dfs <- dfs |>    tibble::enframe(name = \"set\") |>    tidyr::unnest(cols = c(value)) stars.pval <- function(p.value) {   unclass(     symnum(p.value,       corr = FALSE, na = FALSE,       cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),       symbols = c(\"***\", \"**\", \"*\", \".\", \" \")     )   ) }"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"visual-representation-of-the-data-sets","dir":"Articles","previous_headings":"Combine results","what":"Visual representation of the data sets","title":"Quasi Anscombe data sets","text":"","code":"pxy <- ggplot(dfs, aes(x, y)) +   geom_point(shape = 21, fill = \"gray80\", color = \"gray60\") +   geom_smooth(method = \"lm\", se = FALSE, formula = y ~ x) +   facet_wrap(vars(set))  pxy"},{"path":"https://jkunst.com/klassets/articles/Quasi-Anscombe-data-sets.html","id":"checking-coefficients-and-its-significance","dir":"Articles","previous_headings":"Combine results","what":"Checking Coefficients and its significance","title":"Quasi Anscombe data sets","text":"","code":"df_mods <- dfs |>    dplyr::group_nest(set) |>    dplyr::mutate(     model = map(data, lm, formula = y ~ x),     parameters = map(model, broom::tidy)     # value = map(model, coefficients),     # coef  = map(value, names)     )   dfcoef <- df_mods |>    dplyr::select(set, parameters) |>    tidyr::unnest(cols = c(parameters)) |>    dplyr::mutate(sig = stars.pval(p.value))  dfcoef #> # A tibble: 22 × 7 #>    set      term        estimate std.error statistic  p.value sig   #>    <chr>    <chr>          <dbl>     <dbl>     <dbl>    <dbl> <chr> #>  1 Original (Intercept)     2.74    0.276       9.93 1.74e-16 ***   #>  2 Original x               2.04    0.0533     38.3  1.01e-60 ***   #>  3 Set 2 v1 (Intercept)     2.74    1.18        2.33 2.20e- 2 *     #>  4 Set 2 v1 x               2.04    0.228       8.97 2.11e-14 ***   #>  5 Set 2 v2 (Intercept)     2.74    0.898       3.05 2.94e- 3 **    #>  6 Set 2 v2 x               2.04    0.174      11.8  1.95e-20 ***   #>  7 Set 3 v1 (Intercept)     2.74    1.15        2.37 1.97e- 2 *     #>  8 Set 3 v1 x               2.04    0.223       9.14 8.86e-15 ***   #>  9 Set 3 v2 (Intercept)     2.74    1.05        2.61 1.06e- 2 *     #> 10 Set 3 v2 x               2.04    0.203      10.0  9.74e-17 ***   #> # … with 12 more rows  dfcoef |>    dplyr::select(set, term, estimate) |>    tidyr::pivot_wider(names_from = \"term\", values_from = \"estimate\") #> # A tibble: 11 × 3 #>    set      `(Intercept)`     x #>    <chr>            <dbl> <dbl> #>  1 Original          2.74  2.04 #>  2 Set 2 v1          2.74  2.04 #>  3 Set 2 v2          2.74  2.04 #>  4 Set 3 v1          2.74  2.04 #>  5 Set 3 v2          2.74  2.04 #>  6 Set 4 v1          2.74  2.04 #>  7 Set 4 v2          2.74  2.04 #>  8 Set 5 v1          2.74  2.04 #>  9 Set 5 v2          2.74  2.04 #> 10 Set 6 v1          2.74  2.04 #> 11 Set 6 v2          2.74  2.04"},{"path":"https://jkunst.com/klassets/articles/Regression.html","id":"generating-data-set","dir":"Articles","previous_headings":"","what":"Generating data set","title":"Regression","text":"main function sim_xy, need define: number observations simulate. Values \\(\\beta_0\\) \\(\\beta_1\\). distribution sample \\(x\\). example stats::runif purrr::partial(stats::rnorm, mean = 5, sd = 1). function sample error values like purrr::partial(stats::rnorm, sd = 0.5).  can modify data frame get types relationships.","code":"library(klassets) library(ggplot2) library(patchwork)  set.seed(123)  df_default <- sim_xy()  df_default #> # A tibble: 100 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.69  3.99 #>  2  3.03  4.65 #>  3  3.31  4.53 #>  4  3.45  4.55 #>  5  3.73  4.39 #>  6  3.73  4.84 #>  7  3.78  4.50 #>  8  3.86  4.10 #>  9  3.88  4.75 #> 10  3.93  5.42 #> # … with 90 more rows  plot(df_default) df <- sim_xy(n = 1000, x_dist = runif)  df <- dplyr::mutate(df, y = y + 2*sin(5 * x))  plot(df)"},{"path":[]},{"path":"https://jkunst.com/klassets/articles/Regression.html","id":"linear-regression","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Linear Regression","title":"Regression","text":"function uses stats::lm fit model.  default model use order = 1 variables, .e, response ~ x + y. can get better fit increase order.  Testing various orders.","code":"df_lr <- fit_linear_model(df)  df_lr #> # A tibble: 1,000 × 3 #>           x     y prediction #>       <dbl> <dbl>      <dbl> #>  1 0.000465  2.64       5.24 #>  2 0.00116   2.24       5.24 #>  3 0.00119   2.67       5.24 #>  4 0.00248   3.09       5.24 #>  5 0.00368   2.36       5.23 #>  6 0.00390   3.34       5.23 #>  7 0.00411   3.19       5.23 #>  8 0.00464   2.60       5.23 #>  9 0.00484   3.16       5.23 #> 10 0.00683   3.45       5.22 #> # … with 990 more rows  plot(df_lr) df_lr2 <- fit_linear_model(df, order = 4, stepwise = TRUE)  attr(df_lr2, \"model\") #>  #> Call: #> stats::lm(formula = y ~ x + x_2 + x_3 + x_4, data = df) #>  #> Coefficients: #> (Intercept)            x          x_2          x_3          x_4   #>       2.932       13.711      -18.046      -16.697       19.801  plot(df_lr2) orders <- c(1, 2, 3, 4)  orders |>    purrr::map(fit_linear_model, df = df) |>    purrr::map(plot) |>    purrr::reduce(`+`) +   patchwork::plot_layout(guides = \"collect\") &   theme_void() + theme(legend.position = \"none\")"},{"path":"https://jkunst.com/klassets/articles/Regression.html","id":"regression-tree","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Regression Tree","title":"Regression","text":"Internally functions uses partykit::ctree.","code":"df_rt <- fit_regression_tree(df, maxdepth = 2)  plot(df_rt) plot(attr(df_rt, \"model\")) plot(fit_regression_tree(df))"},{"path":"https://jkunst.com/klassets/articles/Regression.html","id":"linear-model-tree","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Linear Model Tree","title":"Regression","text":"Internally functions uses partykit::mltree.","code":"df_lmt <- fit_linear_model_tree(df, maxdepth = 3)  plot(df_lmt) plot(attr(df_lmt, \"model\")) plot(fit_linear_model_tree(df))"},{"path":"https://jkunst.com/klassets/articles/Regression.html","id":"random-forest","dir":"Articles","previous_headings":"Fit classification algorithms","what":"Random Forest","title":"Regression","text":"Internally functions uses partykit::cforest.","code":"df_rf <- fit_regression_random_forest(df)  plot(df_rf) # this will be relative similar to `fit_regression_tree` due  # we are using 1 tree plot(fit_regression_random_forest(df, ntree = 1, maxdepth = Inf))"},{"path":"https://jkunst.com/klassets/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Joshua Kunst. Author, maintainer.","code":""},{"path":"https://jkunst.com/klassets/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kunst J (2022). klassets: Tools simulate data set teach Statical Models ML Algorithms. https://jkunst.com/klassets/, https://github.com/jbkunst/klassets.","code":"@Manual{,   title = {klassets: Tools to simulate data set to teach Statical Models and ML Algorithms},   author = {Joshua Kunst},   year = {2022},   note = {https://jkunst.com/klassets/, https://github.com/jbkunst/klassets}, }"},{"path":"https://jkunst.com/klassets/index.html","id":"klassets","dir":"","previous_headings":"","what":"Tools to simulate data set to teach Statical Models and ML Algorithms","title":"Tools to simulate data set to teach Statical Models and ML Algorithms","text":"klassets package collection functions simulate data sets : Teach Statistics Models Machine Learning algorithms works. Illustrate certain particular events heteroskedasticity Simpson’s paradox  example:   Another example can done klassets.","code":"library(klassets)  set.seed(123)  df <- sim_quasianscombe_set_1(n = 500, beta0 = 3, beta1 = 0.5)  plot(df) +   ggplot2::labs(subtitle = \"Very similar to the given parameters (3 and 0.5)\") library(patchwork)  df2 <- sim_quasianscombe_set_2(df, fun = sin) df6 <- sim_quasianscombe_set_6(df, groups = 2, b1_factor = -1)  plot(df2) + plot(df6)"},{"path":"https://jkunst.com/klassets/index.html","id":"where-to-start","dir":"","previous_headings":"","what":"Where to start","title":"Tools to simulate data set to teach Statical Models and ML Algorithms","text":"can check: vignette(\"Quasi-Anscombe-data-sets\") know sim_quasianscombe_set* functions family. vignette(\"Clustering\") see clustering functions.","code":""},{"path":"https://jkunst.com/klassets/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools to simulate data set to teach Statical Models and ML Algorithms","text":"can install development version klassets GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"jbkunst/klassets\")"},{"path":"https://jkunst.com/klassets/index.html","id":"why-the-name-klassets","dir":"","previous_headings":"","what":"Why the name Klassets?","title":"Tools to simulate data set to teach Statical Models and ML Algorithms","text":"Just weird merge Class/Klass sets.","code":""},{"path":"https://jkunst.com/klassets/index.html","id":"inspirationsimilar-ideas","dir":"","previous_headings":"","what":"Inspiration/Similar Ideas","title":"Tools to simulate data set to teach Statical Models and ML Algorithms","text":"https://jumpingrivers.github.io/datasauRus/ https://eliocamp.github.io/metamer/ http://www.econometricsbysimulation.com/2019/03/-importance--graphing--data.html almost , approach ’s different.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_classification_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit classification tree to klassets_response_xy object — fit_classification_tree","title":"Fit classification tree to klassets_response_xy object — fit_classification_tree","text":"Fit classification tree klassets_response_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_classification_tree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit classification tree to klassets_response_xy object — fit_classification_tree","text":"","code":"fit_classification_tree(df, maxdepth = Inf, alpha = 0.05, type = \"prob\", ...)"},{"path":"https://jkunst.com/klassets/reference/fit_classification_tree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit classification tree to klassets_response_xy object — fit_classification_tree","text":"df object sim_response_xy. maxdepth Max depth tree. used partykit::ctree_control. alpha Alpha value, used partykit::ctree_control type Type prediction, one prob, response, node. ... Options partykit::ctree_control.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_classification_tree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit classification tree to klassets_response_xy object — fit_classification_tree","text":"","code":"set.seed(123)  df <- sim_response_xy(n = 1000, relationship = function(x, y) x**2 > sin(y))  plot(df)   # default type = \"prob\" df_tree_prob <- fit_classification_tree(df) df_tree_prob #> # A tibble: 1,000 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl>      <dbl> #>  1 FALSE    -0.425  -0.453       0.242 #>  2 FALSE     0.577   0.188       0.564 #>  3 FALSE    -0.182  -0.680       0.242 #>  4 FALSE     0.766   0.707       0.746 #>  5 TRUE      0.881   0.695       0.746 #>  6 TRUE     -0.909  -0.0442      0.242 #>  7 FALSE     0.0562  0.547       0.564 #>  8 FALSE     0.785  -0.409       0.242 #>  9 FALSE     0.103  -0.869       0.242 #> 10 TRUE     -0.0868 -0.119       0.242 #> # … with 990 more rows  df_tree_resp <- fit_classification_tree(df, type = \"response\") df_tree_resp #> # A tibble: 1,000 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl> <fct>      #>  1 FALSE    -0.425  -0.453  TRUE       #>  2 FALSE     0.577   0.188  FALSE      #>  3 FALSE    -0.182  -0.680  TRUE       #>  4 FALSE     0.766   0.707  FALSE      #>  5 TRUE      0.881   0.695  FALSE      #>  6 TRUE     -0.909  -0.0442 TRUE       #>  7 FALSE     0.0562  0.547  FALSE      #>  8 FALSE     0.785  -0.409  TRUE       #>  9 FALSE     0.103  -0.869  TRUE       #> 10 TRUE     -0.0868 -0.119  TRUE       #> # … with 990 more rows  df_tree_node <- fit_classification_tree(df, type = \"node\") df_tree_node #> # A tibble: 1,000 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl>      <int> #>  1 FALSE    -0.425  -0.453           2 #>  2 FALSE     0.577   0.188           4 #>  3 FALSE    -0.182  -0.680           2 #>  4 FALSE     0.766   0.707           5 #>  5 TRUE      0.881   0.695           5 #>  6 TRUE     -0.909  -0.0442          2 #>  7 FALSE     0.0562  0.547           4 #>  8 FALSE     0.785  -0.409           2 #>  9 FALSE     0.103  -0.869           2 #> 10 TRUE     -0.0868 -0.119           2 #> # … with 990 more rows  plot(df_tree_prob)  plot(df_tree_resp)  plot(df_tree_node)"},{"path":"https://jkunst.com/klassets/reference/fit_hclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Hierarchical Clustering to klassets_cluster object using stats::hclust — fit_hclust","title":"Fit Hierarchical Clustering to klassets_cluster object using stats::hclust — fit_hclust","text":"Fit Hierarchical Clustering klassets_cluster object using stats::hclust","code":""},{"path":"https://jkunst.com/klassets/reference/fit_hclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Hierarchical Clustering to klassets_cluster object using stats::hclust — fit_hclust","text":"","code":"fit_hclust(df, k = 3, method = \"complete\")"},{"path":"https://jkunst.com/klassets/reference/fit_hclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Hierarchical Clustering to klassets_cluster object using stats::hclust — fit_hclust","text":"df klassets_cluster object. k numeric determine number clusters. value passed stats::cutree method. method agglomeration method used.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_hclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Hierarchical Clustering to klassets_cluster object using stats::hclust — fit_hclust","text":"","code":"set.seed(12)  df <- sim_groups(n = 200, groups = 3)  plot(df)   dfhc <- fit_hclust(df, k = 4)  plot(dfhc)"},{"path":"https://jkunst.com/klassets/reference/fit_kmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit K-means to klassets_cluster object — fit_kmeans","title":"Fit K-means to klassets_cluster object — fit_kmeans","text":"Fit K-means klassets_cluster object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_kmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit K-means to klassets_cluster object — fit_kmeans","text":"","code":"fit_kmeans(df, centers = 3, ...)"},{"path":"https://jkunst.com/klassets/reference/fit_kmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit K-means to klassets_cluster object — fit_kmeans","text":"df klassets_cluster object. object sim_groups. centers numeric value pass kmeans_iterations function famous k parameter. ... Extra parameters kmeans_iterations function.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_kmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit K-means to klassets_cluster object — fit_kmeans","text":"","code":"set.seed(12)  df <- sim_groups(n = 200, groups = 3)  plot(df)   set.seed(124)  dfc <- fit_kmeans(df, centers = 4, max_iterations = 6)  plot(dfc)"},{"path":"https://jkunst.com/klassets/reference/fit_knn.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit K Nearest Neighbours to klassets_response_xy object — fit_knn","title":"Fit K Nearest Neighbours to klassets_response_xy object — fit_knn","text":"Fit K Nearest Neighbours klassets_response_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_knn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit K Nearest Neighbours to klassets_response_xy object — fit_knn","text":"","code":"fit_knn(df, neighbours = 10, type = \"prob\")"},{"path":"https://jkunst.com/klassets/reference/fit_knn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit K Nearest Neighbours to klassets_response_xy object — fit_knn","text":"df object sim_response_xy. neighbours neighbours parameter. type Type prediction, one prob response.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_knn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit K Nearest Neighbours to klassets_response_xy object — fit_knn","text":"","code":"set.seed(123)  df <- sim_response_xy(n = 1000, relationship = function(x, y) x**2 > sin(y))  plot(df)   # defaults to prob fit_knn(df) #> # A tibble: 1,000 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl>      <dbl> #>  1 FALSE    -0.425  -0.453       0.9   #>  2 FALSE     0.577   0.188       0.818 #>  3 FALSE    -0.182  -0.680       0.6   #>  4 FALSE     0.766   0.707       0.5   #>  5 TRUE      0.881   0.695       0.9   #>  6 TRUE     -0.909  -0.0442      0.7   #>  7 FALSE     0.0562  0.547       0.7   #>  8 FALSE     0.785  -0.409       0.8   #>  9 FALSE     0.103  -0.869       0.7   #> 10 TRUE     -0.0868 -0.119       0.7   #> # … with 990 more rows  fit_knn(df, type = \"response\") #> # A tibble: 1,000 × 4 #>    response       x       y prediction #>    <fct>      <dbl>   <dbl> <fct>      #>  1 FALSE    -0.425  -0.453  TRUE       #>  2 FALSE     0.577   0.188  TRUE       #>  3 FALSE    -0.182  -0.680  TRUE       #>  4 FALSE     0.766   0.707  FALSE      #>  5 TRUE      0.881   0.695  TRUE       #>  6 TRUE     -0.909  -0.0442 TRUE       #>  7 FALSE     0.0562  0.547  FALSE      #>  8 FALSE     0.785  -0.409  TRUE       #>  9 FALSE     0.103  -0.869  TRUE       #> 10 TRUE     -0.0868 -0.119  TRUE       #> # … with 990 more rows  plot(fit_knn(df))   plot(fit_knn(df, neighbours = 3))   plot(fit_knn(df, neighbours = 10))   plot(fit_knn(df, neighbours = 200))   plot(fit_knn(df, neighbours = 3, type = \"response\"))   plot(fit_knn(df, neighbours = 10, type = \"response\"))   plot(fit_knn(df, neighbours = 200, type = \"response\"))"},{"path":"https://jkunst.com/klassets/reference/fit_linear_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Linear model to klassets_xy object — fit_linear_model","title":"Fit Linear model to klassets_xy object — fit_linear_model","text":"Fit Linear model klassets_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_linear_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Linear model to klassets_xy object — fit_linear_model","text":"","code":"fit_linear_model(df, order = 1, stepwise = FALSE, verbose = FALSE)"},{"path":"https://jkunst.com/klassets/reference/fit_linear_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Linear model to klassets_xy object — fit_linear_model","text":"df object sim_response_xy. order Order predictive variable x. stepwise logical value indicate perform stepwise. verbose logical value indicate show trace stepwise procedure.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_linear_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Linear model to klassets_xy object — fit_linear_model","text":"","code":"df <- sim_xy()  df #> # A tibble: 100 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.98  4.67 #>  2  3.25  4.17 #>  3  3.66  4.53 #>  4  3.70  4.60 #>  5  3.71  4.59 #>  6  3.73  4.72 #>  7  3.77  4.86 #>  8  3.85  4.53 #>  9  3.92  3.84 #> 10  3.94  5.98 #> # … with 90 more rows  dflm <- fit_linear_model(df)  dflm #> # A tibble: 100 × 3 #>        x     y prediction #>    <dbl> <dbl>      <dbl> #>  1  2.98  4.67       4.31 #>  2  3.25  4.17       4.46 #>  3  3.66  4.53       4.69 #>  4  3.70  4.60       4.71 #>  5  3.71  4.59       4.71 #>  6  3.73  4.72       4.73 #>  7  3.77  4.86       4.75 #>  8  3.85  4.53       4.79 #>  9  3.92  3.84       4.83 #> 10  3.94  5.98       4.84 #> # … with 90 more rows  plot(dflm)   df <- sim_xy(1000) df <- dplyr::mutate(df, y = y + 10 * sin(x) + sqrt(abs(x)))  plot(df)   plot(fit_linear_model(df))   plot(fit_linear_model(df, order = 5, stepwise = TRUE, verbose = TRUE)) #> Start:  AIC=-1254.71 #> y ~ x + x_2 + x_3 + x_4 + x_5 #>  #>        Df Sum of Sq    RSS      AIC #> <none>              281.76 -1254.71 #> - x_5   1    14.080 295.84 -1207.94 #> - x_4   1    40.925 322.68 -1121.08 #> - x_3   1    79.761 361.52 -1007.44 #> - x     1   110.750 392.51  -925.20 #> - x_2   1   112.313 394.07  -921.22"},{"path":"https://jkunst.com/klassets/reference/fit_linear_model_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Linear Model tree to klassets_xy object — fit_linear_model_tree","title":"Fit Linear Model tree to klassets_xy object — fit_linear_model_tree","text":"Fit Linear Model tree klassets_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_linear_model_tree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Linear Model tree to klassets_xy object — fit_linear_model_tree","text":"","code":"fit_linear_model_tree(df, maxdepth = Inf, alpha = 0.05, ...)"},{"path":"https://jkunst.com/klassets/reference/fit_linear_model_tree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Linear Model tree to klassets_xy object — fit_linear_model_tree","text":"df object sim_response_xy. maxdepth Max depth tree. used partykit::mob_control. alpha Alpha value, used partykit::mob_control ... Addiotional options passed partykit::mob_control.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_linear_model_tree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Linear Model tree to klassets_xy object — fit_linear_model_tree","text":"","code":"df <- sim_xy()  df #> # A tibble: 100 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.59  4.40 #>  2  2.74  3.73 #>  3  2.76  4.29 #>  4  2.76  4.33 #>  5  3.09  4.37 #>  6  3.17  4.39 #>  7  3.47  4.74 #>  8  3.50  4.75 #>  9  3.59  5.03 #> 10  3.63  5.54 #> # … with 90 more rows  dflm <- fit_linear_model_tree(df)  dflm #> # A tibble: 100 × 3 #>        x     y prediction #>    <dbl> <dbl>      <dbl> #>  1  2.59  4.40       4.43 #>  2  2.74  3.73       4.50 #>  3  2.76  4.29       4.51 #>  4  2.76  4.33       4.51 #>  5  3.09  4.37       4.66 #>  6  3.17  4.39       4.70 #>  7  3.47  4.74       4.84 #>  8  3.50  4.75       4.85 #>  9  3.59  5.03       4.90 #> 10  3.63  5.54       4.92 #> # … with 90 more rows  plot(dflm)   df <- sim_xy(1000) df <- dplyr::mutate(df, y = y + 10 * sin(x) + sqrt(abs(x)))  plot(df)   plot(fit_linear_model_tree(df))"},{"path":"https://jkunst.com/klassets/reference/fit_logistic_regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit Logistic regression to klassets_response_xy object — fit_logistic_regression","title":"Fit Logistic regression to klassets_response_xy object — fit_logistic_regression","text":"Fit Logistic regression klassets_response_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_logistic_regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit Logistic regression to klassets_response_xy object — fit_logistic_regression","text":"","code":"fit_logistic_regression(df, order = 1, stepwise = FALSE, verbose = FALSE)"},{"path":"https://jkunst.com/klassets/reference/fit_logistic_regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit Logistic regression to klassets_response_xy object — fit_logistic_regression","text":"df object sim_response_xy. order Order values x y. stepwise logical value indicate perform stepwise. verbose logical value indicate show trace stepwise procedure.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_logistic_regression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit Logistic regression to klassets_response_xy object — fit_logistic_regression","text":"","code":"set.seed(123)  df <- sim_response_xy(n = 500, relationship = function(x, y) x**2 > y)  plot(df)   df_reg_log <- fit_logistic_regression(df)  plot(df_reg_log)   df_reg_log_3 <- fit_logistic_regression(df, order = 3, stepwise = TRUE)  plot(df_reg_log_3)"},{"path":"https://jkunst.com/klassets/reference/fit_regression_random_forest.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit regression random forest to klassets_xy object — fit_regression_random_forest","title":"Fit regression random forest to klassets_xy object — fit_regression_random_forest","text":"Fit regression random forest klassets_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_regression_random_forest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit regression random forest to klassets_xy object — fit_regression_random_forest","text":"","code":"fit_regression_random_forest(   df,   ntree = 500L,   maxdepth = Inf,   alpha = 0.05,   trace = FALSE,   ... )"},{"path":"https://jkunst.com/klassets/reference/fit_regression_random_forest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit regression random forest to klassets_xy object — fit_regression_random_forest","text":"df object sim_response_xy. ntree Number trees grow forest. maxdepth Max depth tree. used partykit::ctree_control. alpha Alpha value, used partykit::ctree_control trace logical indicating progress bar shall printed forest grows. ... Options partykit::ctree_control.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_regression_random_forest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit regression random forest to klassets_xy object — fit_regression_random_forest","text":"","code":"df <- sim_xy()  df #> # A tibble: 100 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.49  4.53 #>  2  2.96  4.43 #>  3  3.04  5.03 #>  4  3.11  3.98 #>  5  3.15  5.73 #>  6  3.25  4.32 #>  7  3.31  3.92 #>  8  3.33  4.49 #>  9  3.38  4.76 #> 10  3.43  5.53 #> # … with 90 more rows  dflm <- fit_regression_random_forest(df)  dflm #> # A tibble: 100 × 3 #>        x     y prediction #>    <dbl> <dbl>      <dbl> #>  1  2.49  4.53       4.77 #>  2  2.96  4.43       4.77 #>  3  3.04  5.03       4.77 #>  4  3.11  3.98       4.77 #>  5  3.15  5.73       4.77 #>  6  3.25  4.32       4.77 #>  7  3.31  3.92       4.77 #>  8  3.33  4.49       4.77 #>  9  3.38  4.76       4.77 #> 10  3.43  5.53       4.78 #> # … with 90 more rows  plot(dflm)   df <- sim_xy(1000) df <- dplyr::mutate(df, y = y + 3 * sin(x) + 5 * sqrt(abs(x)))  plot(df)   plot(fit_regression_random_forest(df))   # default plot(fit_regression_random_forest(df))"},{"path":"https://jkunst.com/klassets/reference/fit_regression_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit regression tree to klassets_xy object — fit_regression_tree","title":"Fit regression tree to klassets_xy object — fit_regression_tree","text":"Fit regression tree klassets_xy object","code":""},{"path":"https://jkunst.com/klassets/reference/fit_regression_tree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit regression tree to klassets_xy object — fit_regression_tree","text":"","code":"fit_regression_tree(df, maxdepth = Inf, alpha = 0.05, ...)"},{"path":"https://jkunst.com/klassets/reference/fit_regression_tree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit regression tree to klassets_xy object — fit_regression_tree","text":"df object sim_response_xy. maxdepth Max depth tree. used partykit::ctree_control. alpha Alpha value, used partykit::ctree_control ... Options partykit::ctree_control.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_regression_tree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit regression tree to klassets_xy object — fit_regression_tree","text":"","code":"df <- sim_xy()  df #> # A tibble: 100 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.36  3.92 #>  2  2.75  4.83 #>  3  2.86  4.34 #>  4  2.93  3.99 #>  5  3.03  4.07 #>  6  3.20  4.66 #>  7  3.21  3.74 #>  8  3.29  4.79 #>  9  3.30  5.13 #> 10  3.31  4.42 #> # … with 90 more rows  dflm <- fit_regression_tree(df)  dflm #> # A tibble: 100 × 3 #>        x     y prediction #>    <dbl> <dbl>      <dbl> #>  1  2.36  3.92       4.22 #>  2  2.75  4.83       4.22 #>  3  2.86  4.34       4.22 #>  4  2.93  3.99       4.22 #>  5  3.03  4.07       4.22 #>  6  3.20  4.66       4.22 #>  7  3.21  3.74       4.22 #>  8  3.29  4.79       5.10 #>  9  3.30  5.13       5.10 #> 10  3.31  4.42       5.10 #> # … with 90 more rows  plot(dflm)   df <- sim_xy(1000) df <- dplyr::mutate(df, y = y + 10 * sin(x) + sqrt(abs(x)))  plot(df)   plot(fit_regression_tree(df, maxdepth = 3))   # default plot(fit_regression_tree(df))"},{"path":"https://jkunst.com/klassets/reference/fit_statskmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit K-means to klassets_cluster object using stats::kmeans — fit_statskmeans","title":"Fit K-means to klassets_cluster object using stats::kmeans — fit_statskmeans","text":"Fit K-means klassets_cluster object using stats::kmeans","code":""},{"path":"https://jkunst.com/klassets/reference/fit_statskmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit K-means to klassets_cluster object using stats::kmeans — fit_statskmeans","text":"","code":"fit_statskmeans(df, centers = 3, ...)"},{"path":"https://jkunst.com/klassets/reference/fit_statskmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit K-means to klassets_cluster object using stats::kmeans — fit_statskmeans","text":"df klassets_cluster object. centers numeric value pass stats::kmeans method. famous k parameter. ... Extra parameter stats::kmeans function.","code":""},{"path":"https://jkunst.com/klassets/reference/fit_statskmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit K-means to klassets_cluster object using stats::kmeans — fit_statskmeans","text":"","code":"set.seed(12)  df <- sim_groups(n = 200, groups = 3)  plot(df)   dfc <- fit_statskmeans(df, centers = 4)  plot(dfc)"},{"path":"https://jkunst.com/klassets/reference/kmeans_iterations.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate intermediate iterations when performing K-means — kmeans_iterations","title":"Generate intermediate iterations when performing K-means — kmeans_iterations","text":"Generate intermediate iterations performing K-means","code":""},{"path":"https://jkunst.com/klassets/reference/kmeans_iterations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate intermediate iterations when performing K-means — kmeans_iterations","text":"","code":"kmeans_iterations(   df,   centers = 3,   tolerance = 1e-05,   max_iterations = 15,   verbose = FALSE )"},{"path":"https://jkunst.com/klassets/reference/kmeans_iterations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate intermediate iterations when performing K-means — kmeans_iterations","text":"df object sim_groups. centers many clusters. tolerance value indicating early stop. max_iterations Max iterations calculate. verbose logical value, show iterations messages.","code":""},{"path":"https://jkunst.com/klassets/reference/kmeans_iterations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate intermediate iterations when performing K-means — kmeans_iterations","text":"","code":"set.seed(12)  df <- sim_groups(n = 200, groups = 3)  plot(df)   set.seed(124)  kmi <- kmeans_iterations(df, centers = 4, max_iterations = 6)  plot(kmi)"},{"path":"https://jkunst.com/klassets/reference/sim_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate data sets to apply clustering algorithms — sim_groups","title":"Generate data sets to apply clustering algorithms — sim_groups","text":"Generate data sets apply clustering algorithms","code":""},{"path":"https://jkunst.com/klassets/reference/sim_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate data sets to apply clustering algorithms — sim_groups","text":"","code":"sim_groups(n = 1000, groups = 3, props = NULL)"},{"path":"https://jkunst.com/klassets/reference/sim_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate data sets to apply clustering algorithms — sim_groups","text":"n integer. groups integer props vector probabilities length groups.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_groups.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate data sets to apply clustering algorithms — sim_groups","text":"","code":"set.seed(123456)  df <- sim_groups()  df #> # A tibble: 998 × 3 #>    group       x     y #>    <chr>   <dbl> <dbl> #>  1 1      1.86   -6.89 #>  2 1      1.70   -8.54 #>  3 1      0.485  -7.69 #>  4 1     -0.105  -6.99 #>  5 1      0.508  -8.58 #>  6 1      1.13   -8.27 #>  7 1      1.95   -7.72 #>  8 1      0.245  -6.45 #>  9 1      0.258  -8.72 #> 10 1      0.0439 -8.95 #> # … with 988 more rows  plot(df)   plot(sim_groups(500, 5))"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_1.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate quasi Anscombe data sets Type 1 — sim_quasianscombe_set_1","title":"Generate quasi Anscombe data sets Type 1 — sim_quasianscombe_set_1","text":"function generate data set Type 1  creating first x random vector apply linear transformation using beta0 beta1 finally adding normal distributed noise using error_sd creating y values.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate quasi Anscombe data sets Type 1 — sim_quasianscombe_set_1","text":"","code":"sim_quasianscombe_set_1(   n = 100,   beta0 = 3,   beta1 = 0.5,   x_dist = purrr::partial(rnorm, mean = 5, sd = 1),   error_dist = purrr::partial(rnorm, sd = 0.5) )"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate quasi Anscombe data sets Type 1 — sim_quasianscombe_set_1","text":"n Number observations beta0 beta0, default value: 3, beta1 beta1, default value: 0.5 x_dist random number generation function. Default rnorm mean 5 sd 1. error_dist random number generation function. Default rnorm mean 0 sd 0.5.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate quasi Anscombe data sets Type 1 — sim_quasianscombe_set_1","text":"typical first example regression analysis taught. Internally procedure sim_xy.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate quasi Anscombe data sets Type 1 — sim_quasianscombe_set_1","text":"","code":"df <- sim_quasianscombe_set_1()  df #> # A tibble: 100 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.90  4.83 #>  2  3.18  3.93 #>  3  3.25  4.48 #>  4  3.29  3.95 #>  5  3.51  5.23 #>  6  3.54  4.66 #>  7  3.54  4.96 #>  8  3.55  5.08 #>  9  3.58  5.01 #> 10  3.58  4.60 #> # … with 90 more rows  plot(df)   plot(df, add_lm = FALSE)   plot(sim_quasianscombe_set_1(n = 1000))   plot(sim_quasianscombe_set_1(n = 1000, beta0 = 0, beta1 = 1, x_dist = runif))"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_2.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate quasi Anscombe data sets Type 2: No linear relationship — sim_quasianscombe_set_2","title":"Generate quasi Anscombe data sets Type 2: No linear relationship — sim_quasianscombe_set_2","text":"Data sets Type 2 shows linear realtionship x y can lead regression model (terms parameter values) Type 1.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate quasi Anscombe data sets Type 2: No linear relationship — sim_quasianscombe_set_2","text":"","code":"sim_quasianscombe_set_2(   df,   fun = function(x) {      x^2  },   residual_factor = 0.25 )"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate quasi Anscombe data sets Type 2: No linear relationship — sim_quasianscombe_set_2","text":"df data frame sim_quasianscombe_set_1 (similar). fun function apply, applied normalized version x. residual_factor Numeric value multiply residual modify variance.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate quasi Anscombe data sets Type 2: No linear relationship — sim_quasianscombe_set_2","text":"","code":"df <- sim_quasianscombe_set_1()  dataset2 <- sim_quasianscombe_set_2(df)  dataset2 #> # A tibble: 100 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.21  9.42 #>  2  2.67  7.44 #>  3  2.96  6.50 #>  4  3.10  6.27 #>  5  3.11  6.14 #>  6  3.13  5.97 #>  7  3.23  5.90 #>  8  3.47  5.46 #>  9  3.50  5.31 #> 10  3.59  5.15 #> # … with 90 more rows  plot(dataset2)   plot(sim_quasianscombe_set_2(df, residual_factor = 0))   fun1 <- function(x){ 2 * sin(x*diff(range(x))) }  plot(sim_quasianscombe_set_2(df, fun = fun1))   fun2 <- abs  plot(sim_quasianscombe_set_2(df, fun = fun2))   fun3 <- function(x){ (x - mean(x)) * sin(x*diff(range(x))) }  plot(sim_quasianscombe_set_2(df, fun = fun3))"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_3.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate quasi Anscombe data sets Type 3: Extreme values (a.k.a Outliers) — sim_quasianscombe_set_3","title":"Generate quasi Anscombe data sets Type 3: Extreme values (a.k.a Outliers) — sim_quasianscombe_set_3","text":"Data sets Type 3 get outliers conserving $x$ mean coefficients -different significance- adjusted linear model.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate quasi Anscombe data sets Type 3: Extreme values (a.k.a Outliers) — sim_quasianscombe_set_3","text":"","code":"sim_quasianscombe_set_3(   df,   prop = 0.05,   beta1_factor = 0.5,   residual_factor = 0.25 )"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate quasi Anscombe data sets Type 3: Extreme values (a.k.a Outliers) — sim_quasianscombe_set_3","text":"df data frame sim_quasianscombe_set_1 (similar). prop proportion value modify outliers. beta1_factor Numeric value modify beta1 value. residual_factor Numeric value multiply residual modify variance.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_3.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate quasi Anscombe data sets Type 3: Extreme values (a.k.a Outliers) — sim_quasianscombe_set_3","text":"function : Calculate linear regression model calculate new trend using 0.5 times beta1 Take prop% values greater 2*prop x values modify related y value get original estimation beta1 Apply residual_factor factor residual get minor variance better visual impression outliers effect.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_3.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate quasi Anscombe data sets Type 3: Extreme values (a.k.a Outliers) — sim_quasianscombe_set_3","text":"","code":"df <- sim_quasianscombe_set_1()  dataset3 <- sim_quasianscombe_set_3(df)  dataset3 #> # A tibble: 100 × 2 #>        x     y #>    <dbl> <dbl> #>  1  3.43  4.81 #>  2  3.57  4.80 #>  3  3.58  5.10 #>  4  3.59  5.03 #>  5  3.66  5.24 #>  6  3.67  5.06 #>  7  3.73  5.35 #>  8  3.74  5.07 #>  9  3.77  5.19 #> 10  3.82  5.20 #> # … with 90 more rows  plot(dataset3)   plot(sim_quasianscombe_set_3(df, prop = 0.1, residual_factor = 0))"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_4.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate quasi Anscombe data sets Type 4: 2 Clusters — sim_quasianscombe_set_4","title":"Generate quasi Anscombe data sets Type 4: 2 Clusters — sim_quasianscombe_set_4","text":"Data sets Type 4 recreate two cluster keeping coefficient original regression model.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_4.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate quasi Anscombe data sets Type 4: 2 Clusters — sim_quasianscombe_set_4","text":"","code":"sim_quasianscombe_set_4(df, rescale_to = c(0.1, 0.2), prop = 0.15)"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_4.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate quasi Anscombe data sets Type 4: 2 Clusters — sim_quasianscombe_set_4","text":"df data frame sim_quasianscombe_set_1 (similar). rescale_to Rescale x value create second cluster. prop proportion value modify second group/cluster.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_4.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate quasi Anscombe data sets Type 4: 2 Clusters — sim_quasianscombe_set_4","text":"function : Disorder order x values. Rescale x value specific original quantiles. take proportion value translate left keeping original mean x. Finally add value associated y value subtract complement group regression model terms coefficients.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_4.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate quasi Anscombe data sets Type 4: 2 Clusters — sim_quasianscombe_set_4","text":"","code":"df <- sim_quasianscombe_set_1()  dataset4 <- sim_quasianscombe_set_4(df)  dataset4 #> # A tibble: 100 × 2 #>        x     y #>    <dbl> <dbl> #>  1  3.80  5.54 #>  2  3.90  5.10 #>  3  3.91  3.72 #>  4  3.91  5.02 #>  5  3.91  4.67 #>  6  3.91  4.27 #>  7  3.92  6.39 #>  8  3.93  4.27 #>  9  3.93  6.13 #> 10  3.93  6.46 #> # … with 90 more rows  plot(dataset4)   plot(sim_quasianscombe_set_4(df, rescale_to = c(0, .1), prop = 0.5))"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_5.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate quasi Anscombe data sets Type 5: Heteroskedasticity — sim_quasianscombe_set_5","title":"Generate quasi Anscombe data sets Type 5: Heteroskedasticity — sim_quasianscombe_set_5","text":"Data sets Type 5 recreates phenomenon heteroskedasticity residuals.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_5.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate quasi Anscombe data sets Type 5: Heteroskedasticity — sim_quasianscombe_set_5","text":"","code":"sim_quasianscombe_set_5(df, fun = identity, residual_factor = 10)"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_5.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate quasi Anscombe data sets Type 5: Heteroskedasticity — sim_quasianscombe_set_5","text":"df data frame sim_quasianscombe_set_1 (similar). fun function apply index multiply residuals original model. residual_factor Numeric value multiply residual modify variance.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_5.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate quasi Anscombe data sets Type 5: Heteroskedasticity — sim_quasianscombe_set_5","text":"function take residuals $e_i$ get $e'_i = e_i * fun()$ rescale $e'_i$ range $e_i$.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_5.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate quasi Anscombe data sets Type 5: Heteroskedasticity — sim_quasianscombe_set_5","text":"","code":"df <- sim_quasianscombe_set_1()  dataset5 <- sim_quasianscombe_set_5(df)  dataset5 #> # A tibble: 100 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.37  3.80 #>  2  2.39  3.96 #>  3  3.21  4.49 #>  4  3.33  4.46 #>  5  3.34  4.34 #>  6  3.46  4.49 #>  7  3.55  4.27 #>  8  3.60  4.09 #>  9  3.62  3.93 #> 10  3.65  4.40 #> # … with 90 more rows  plot(dataset5)   plot(sim_quasianscombe_set_5(df, fun = rev))   plot(sim_quasianscombe_set_5(df, fun = sqrt))   plot(sim_quasianscombe_set_5(df, fun = log))   plot(sim_quasianscombe_set_5(df, fun = function(x) x^(1+0.6)))"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_6.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate quasi Anscombe data sets Type 6: Simpson's Paradox — sim_quasianscombe_set_6","title":"Generate quasi Anscombe data sets Type 6: Simpson's Paradox — sim_quasianscombe_set_6","text":"Data sets Type 6 recreates phenomenon Simpon's paradox.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_6.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate quasi Anscombe data sets Type 6: Simpson's Paradox — sim_quasianscombe_set_6","text":"","code":"sim_quasianscombe_set_6(df, groups = 3, b1_factor = -1, residual_factor = 0.25)"},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_6.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate quasi Anscombe data sets Type 6: Simpson's Paradox — sim_quasianscombe_set_6","text":"df data frame sim_quasianscombe_set_1 (similar). groups Number groups separate x values. b1_factor numeric value get slope group $beta_1$. residual_factor Numeric value multiply residual modify variance.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_6.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate quasi Anscombe data sets Type 6: Simpson's Paradox — sim_quasianscombe_set_6","text":"function take x vector separate groups groups apply local model modified regression using b1_factor factor. residual multiply value 0 1 make visual effect greater.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_quasianscombe_set_6.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate quasi Anscombe data sets Type 6: Simpson's Paradox — sim_quasianscombe_set_6","text":"","code":"df <- sim_quasianscombe_set_1()  dataset6 <- sim_quasianscombe_set_6(df)  dataset6 #> # A tibble: 100 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.17  5.54 #>  2  2.41  5.40 #>  3  2.68  5.44 #>  4  3.34  5.01 #>  5  3.44  4.81 #>  6  3.61  4.83 #>  7  3.61  4.77 #>  8  3.73  4.68 #>  9  3.80  4.74 #> 10  3.82  4.69 #> # … with 90 more rows  plot(dataset6)"},{"path":"https://jkunst.com/klassets/reference/sim_response_xy.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate data sets to apply binary classifiers — sim_response_xy","title":"Generate data sets to apply binary classifiers — sim_response_xy","text":"Generate data sets apply binary classifiers","code":""},{"path":"https://jkunst.com/klassets/reference/sim_response_xy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate data sets to apply binary classifiers — sim_response_xy","text":"","code":"sim_response_xy(   n = 100,   x_dist = purrr::partial(runif, min = -1, max = 1),   y_dist = x_dist,   relationship = function(x, y) x > y,   noise = 0.2 )"},{"path":"https://jkunst.com/klassets/reference/sim_response_xy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate data sets to apply binary classifiers — sim_response_xy","text":"n intenger x_dist random number generation function. y_dist random number generation function. relationship function specify relationship x, y response. function f(x, y) need return logical value. noise number 0 1.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_response_xy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate data sets to apply binary classifiers — sim_response_xy","text":"","code":"set.seed(123)  df <- sim_response_xy(n = 500)  df #> # A tibble: 500 × 3 #>    response       x        y #>    <fct>      <dbl>    <dbl> #>  1 FALSE    -0.425  -0.293   #>  2 TRUE      0.577  -0.267   #>  3 FALSE    -0.182  -0.426   #>  4 TRUE      0.766  -0.840   #>  5 TRUE      0.881  -0.269   #>  6 FALSE    -0.909  -0.644   #>  7 FALSE     0.0562  0.0721  #>  8 TRUE      0.785   0.00790 #>  9 TRUE      0.103   0.890   #> 10 TRUE     -0.0868 -0.317   #> # … with 490 more rows  plot(df)"},{"path":"https://jkunst.com/klassets/reference/sim_xy.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate data sets to apply regression methods — sim_xy","title":"Generate data sets to apply regression methods — sim_xy","text":"Generate data sets apply regression methods","code":""},{"path":"https://jkunst.com/klassets/reference/sim_xy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate data sets to apply regression methods — sim_xy","text":"","code":"sim_xy(   n = 100,   beta0 = 3,   beta1 = 0.5,   x_dist = purrr::partial(rnorm, mean = 5, sd = 1),   error_dist = purrr::partial(rnorm, sd = 0.5) )"},{"path":"https://jkunst.com/klassets/reference/sim_xy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate data sets to apply regression methods — sim_xy","text":"n Number observations beta0 beta0, default value: 3, beta1 beta1, default value: 0.5 x_dist random number generation function. Default rnorm mean 5 sd 1. error_dist random number generation function. Default rnorm mean 0 sd 0.5.","code":""},{"path":"https://jkunst.com/klassets/reference/sim_xy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate data sets to apply regression methods — sim_xy","text":"","code":"df <- sim_xy()  df #> # A tibble: 100 × 2 #>        x     y #>    <dbl> <dbl> #>  1  2.49  4.53 #>  2  2.96  4.43 #>  3  3.04  5.03 #>  4  3.11  3.98 #>  5  3.15  5.73 #>  6  3.25  4.32 #>  7  3.31  3.92 #>  8  3.33  4.49 #>  9  3.38  4.76 #> 10  3.43  5.53 #> # … with 90 more rows  plot(df)   klassets:::plot.klassets_xy(setNames(cars, c(\"x\", \"y\")))"}]
